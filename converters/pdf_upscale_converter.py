#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDFé«˜æ¸…åŒ–è½¬æ¢å™¨

ä½¿ç”¨Waifu2xå¯¹PDFä¸­çš„å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†
"""

import os
import fitz  # PyMuPDF
import tempfile
import logging
from typing import Dict, Any, List
from PIL import Image
import io
import subprocess
import sys
import numpy as np

# å¯¼å…¥åŸºç±»
from converters.converter_interface import ConverterInterface, ConverterMetadata

# å¯¼å…¥æ–°çš„æ¨¡å—åŒ–ç»„ä»¶
from converters.image_processing_toolkit import ImageAnalyzer, ImageProcessingPipeline
from converters.config_manager import get_config_manager, get_processing_config
from converters.enhancement_plugins import get_plugin_manager

logger = logging.getLogger('pdf_converter')

class PDFUpscaleConverter(ConverterInterface):
    """PDFé«˜æ¸…åŒ–è½¬æ¢å™¨
    
    ä½¿ç”¨Real-ESRGANå’ŒWaifu2xå¯¹PDFä¸­çš„å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡å¤„ç†
    """
    
    def __init__(self):
        self._temp_files = []
        self._check_dependencies()
        self._setup_gpu_environment()
        
        # åˆå§‹åŒ–æ–°çš„æ¨¡å—åŒ–ç»„ä»¶
        self.config_manager = get_config_manager()
        self.config = get_processing_config()
        self.image_analyzer = ImageAnalyzer()
        self.plugin_manager = get_plugin_manager()
        
        # æ³¨å†Œå†…ç½®æ’ä»¶
        self._register_builtin_plugins()
    
    def _register_builtin_plugins(self):
        """æ³¨å†Œå†…ç½®çš„å›¾åƒå¤„ç†æ’ä»¶"""
        from converters.enhancement_plugins import (
            CLAHEPreprocessingPlugin, SmartSharpeningPlugin,
            NoiseReductionPlugin, ColorEnhancementPlugin
        )
        
        # æ³¨å†Œé¢„å¤„ç†æ’ä»¶
        self.plugin_manager.register_plugin(CLAHEPreprocessingPlugin())
        self.plugin_manager.register_plugin(SmartSharpeningPlugin())
        
        # æ³¨å†Œåå¤„ç†æ’ä»¶
        self.plugin_manager.register_plugin(NoiseReductionPlugin())
        self.plugin_manager.register_plugin(ColorEnhancementPlugin())
    
    @property
    def name(self) -> str:
        return "pdf_upscale"
    
    @property
    def description(self) -> str:
        return "ä½¿ç”¨AIç®—æ³•å¯¹PDFä¸­çš„å›¾åƒè¿›è¡Œé«˜æ¸…åŒ–å¤„ç†ï¼Œæ”¯æŒåŠ¨æ¼«ã€ç…§ç‰‡å’Œæ–‡æ¡£ä¸‰ç§æ¨¡å¼"
    
    @property
    def supported_input_formats(self) -> List[str]:
        return ["pdf"]
    
    @property
    def supported_output_formats(self) -> List[str]:
        return ["pdf"]
    
    @property
    def version(self) -> str:
        return "1.0.0"
    
    def get_metadata(self) -> ConverterMetadata:
        """è·å–è½¬æ¢å™¨å…ƒæ•°æ®"""
        return ConverterMetadata(
            name=self.name,
            description=self.description,
            version=self.version,
            supported_input_formats=self.supported_input_formats,
            supported_output_formats=self.supported_output_formats,
            author="PDF Converter Team"
        )
    
    def validate_input(self, input_path: str) -> bool:
        """éªŒè¯PDFæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            if not os.path.exists(input_path):
                return False
            
            if not input_path.lower().endswith('.pdf'):
                return False
            
            # å°è¯•æ‰“å¼€PDFæ–‡ä»¶
            doc = fitz.open(input_path)
            page_count = len(doc)
            doc.close()
            
            return page_count > 0
        except Exception as e:
            logger.error(f"PDFæ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False
    
    def convert(self, input_path: str, output_path: str, **kwargs) -> dict:
        """æ‰§è¡ŒPDFé«˜æ¸…åŒ–è½¬æ¢
        
        Args:
            input_path: è¾“å…¥PDFæ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºPDFæ–‡ä»¶è·¯å¾„
            **kwargs: è½¬æ¢å‚æ•°ï¼ŒåŒ…å«upscale_method
            
        Returns:
            dict: è½¬æ¢ç»“æœï¼ŒåŒ…å«successå­—æ®µå’Œå¯èƒ½çš„errorä¿¡æ¯
        """
        try:
            upscale_method = kwargs.get('upscale_method', 'photo')
            progress_callback = kwargs.get('progress_callback')
            log_callback = kwargs.get('log_callback')
            enable_gpu = kwargs.get('enable_gpu', True)
            batch_size = kwargs.get('batch_size', 4)
            
            if log_callback:
                log_callback(f"å¼€å§‹PDFé«˜æ¸…åŒ–å¤„ç†: {os.path.basename(input_path)}")
                log_callback(f"é«˜æ¸…åŒ–æ–¹å¼: {self._get_method_description(upscale_method)}")
            
            # æ‰“å¼€PDFæ–‡æ¡£
            doc = fitz.open(input_path)
            total_pages = len(doc)
            
            if log_callback:
                log_callback(f"PDFå…±æœ‰ {total_pages} é¡µ")
            
            # åˆ›å»ºæ–°çš„PDFæ–‡æ¡£
            new_doc = fitz.open()
            
            # GPUå†…å­˜ç®¡ç† - å¢å¼ºåŒæ˜¾å¡è¯Šæ–­
            if log_callback:
                log_callback("ğŸ”§ å¼€å§‹GPUç¯å¢ƒæ£€æµ‹...")
            gpu_available = self._check_gpu_availability(log_callback) and enable_gpu
            if gpu_available and log_callback:
                try:
                    import torch
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                    log_callback(f"ğŸ® GPUä¿¡æ¯: {torch.cuda.get_device_name(0)}, æ˜¾å­˜: {gpu_memory:.1f}GB")
                except:
                    pass
            
            for page_num in range(total_pages):
                if progress_callback:
                    progress_callback(int((page_num / total_pages) * 100))
                
                if log_callback:
                    log_callback(f"å¤„ç†ç¬¬ {page_num + 1}/{total_pages} é¡µ")
                
                # GPUå†…å­˜æ¸…ç†ï¼ˆæ¯10é¡µæ¸…ç†ä¸€æ¬¡ï¼‰
                if gpu_available and page_num % 10 == 0 and page_num > 0:
                    try:
                        import torch
                        torch.cuda.empty_cache()
                        if log_callback:
                            log_callback(f"      ğŸ§¹ æ¸…ç†GPUå†…å­˜ç¼“å­˜")
                    except:
                        pass
                
                page = doc[page_num]
                
                # è·å–é¡µé¢ä¸­çš„å›¾åƒ
                image_list = page.get_images(full=True)
                
                # åˆ›å»ºæ–°é¡µé¢
                new_page = new_doc.new_page(width=page.rect.width, height=page.rect.height)
                
                # å…ˆå¤åˆ¶é¡µé¢çš„éå›¾åƒå†…å®¹ï¼ˆæ–‡å­—ã€çŸ¢é‡å›¾å½¢ç­‰ï¼‰
                new_page.show_pdf_page(new_page.rect, doc, page_num)
                
                if image_list:
                    if log_callback:
                        log_callback(f"  å‘ç° {len(image_list)} ä¸ªå›¾åƒ")
                    
                    # å¤„ç†é¡µé¢ä¸­çš„æ¯ä¸ªå›¾åƒ
                    for img_index, img in enumerate(image_list):
                        if log_callback:
                            log_callback(f"    å¤„ç†å›¾åƒ {img_index + 1}/{len(image_list)}")
                        
                        try:
                            # æå–å›¾åƒæ•°æ®
                            xref = img[0]
                            base_image = doc.extract_image(xref)
                            image_bytes = base_image["image"]
                            image_ext = base_image["ext"]
                            
                            # è·å–å›¾åƒåœ¨é¡µé¢ä¸­çš„ä½ç½®
                            img_rects = page.get_image_rects(xref)
                            if not img_rects:
                                continue
                            
                            # é«˜æ¸…åŒ–å¤„ç†
                            upscaled_image_bytes = self._upscale_image(
                                image_bytes, upscale_method, log_callback, gpu_available
                            )
                            
                            if upscaled_image_bytes:
                                # å…ˆåˆ é™¤åŸå›¾åƒåŒºåŸŸ
                                for img_rect in img_rects:
                                    # ç”¨ç™½è‰²çŸ©å½¢è¦†ç›–åŸå›¾åƒä½ç½®
                                    new_page.draw_rect(img_rect, color=(1, 1, 1), fill=(1, 1, 1))
                                
                                # æ’å…¥é«˜æ¸…åŒ–åçš„å›¾åƒ
                                for img_rect in img_rects:
                                    try:
                                        # åˆ›å»ºä¸´æ—¶å›¾åƒæ–‡ä»¶
                                        import tempfile
                                        temp_img_path = tempfile.mktemp(suffix=f'.{image_ext}')
                                        self._temp_files.append(temp_img_path)
                                        
                                        # ä¿å­˜é«˜æ¸…åŒ–å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
                                        with open(temp_img_path, 'wb') as f:
                                            f.write(upscaled_image_bytes)
                                        
                                        # æ™ºèƒ½è°ƒæ•´å›¾åƒå°ºå¯¸ä»¥å‡å°‘ç•™ç™½
                                        optimized_rect = self._optimize_image_layout(
                                            img_rect, temp_img_path, page, log_callback
                                        )
                                        
                                        # ä½¿ç”¨ä¼˜åŒ–çš„æ–¹æ³•æ’å…¥é«˜æ¸…åŒ–å›¾åƒ
                                        self._insert_upscaled_image(
                                            new_page, optimized_rect, temp_img_path, log_callback
                                        )
                                        
                                        if log_callback:
                                            log_callback(f"      âœ… å›¾åƒ {img_index + 1} é«˜æ¸…åŒ–å®Œæˆ")
                                        
                                    except Exception as e:
                                        if log_callback:
                                            log_callback(f"      âŒ å›¾åƒ {img_index + 1} æ’å…¥å¤±è´¥: {str(e)}")
                                        logger.error(f"å›¾åƒæ’å…¥å¤±è´¥: {e}")
                            else:
                                if log_callback:
                                    log_callback(f"      âš ï¸ å›¾åƒ {img_index + 1} é«˜æ¸…åŒ–å¤±è´¥ï¼Œä¿æŒåŸå›¾")
                        
                        except Exception as e:
                            if log_callback:
                                log_callback(f"      âŒ å›¾åƒ {img_index + 1} å¤„ç†å¤±è´¥: {str(e)}")
                            logger.error(f"å›¾åƒå¤„ç†å¤±è´¥: {e}")
                            continue
            
            # ä¿å­˜æ–°æ–‡æ¡£
            new_doc.save(output_path)
            new_doc.close()
            doc.close()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files()
            
            if log_callback:
                log_callback(f"PDFé«˜æ¸…åŒ–å®Œæˆ: {os.path.basename(output_path)}")
            
            if progress_callback:
                progress_callback(100)
            
            return {"success": True, "output_path": output_path}
            
        except Exception as e:
            logger.error(f"PDFé«˜æ¸…åŒ–å¤±è´¥: {e}")
            if log_callback:
                log_callback(f"âŒ é«˜æ¸…åŒ–å¤±è´¥: {str(e)}")
            # ç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿæ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files()
            return {"success": False, "error": str(e)}
    
    def _upscale_image(self, image_bytes: bytes, method: str, log_callback=None, gpu_available=None) -> bytes:
        """å¯¹å›¾åƒè¿›è¡Œé«˜æ¸…åŒ–å¤„ç†ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
        try:
            # æ£€æŸ¥GPUå¯ç”¨æ€§å’Œå†…å­˜
            if gpu_available is None:
                gpu_available = self._check_gpu_availability(log_callback)
            
            # GPUå†…å­˜æ£€æŸ¥å’Œç®¡ç†
            if gpu_available:
                try:
                    import torch
                    torch.cuda.empty_cache()  # æ¸…ç†GPUç¼“å­˜
                    memory_free = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)
                    memory_free_gb = memory_free / 1024**3
                    
                    if memory_free_gb < 2.0:  # å°‘äº2GBå¯ç”¨å†…å­˜æ—¶é™çº§åˆ°CPU
                        if log_callback:
                            log_callback(f"      âš ï¸ GPUå†…å­˜ä¸è¶³ ({memory_free_gb:.1f}GB)ï¼Œåˆ‡æ¢åˆ°CPUæ¨¡å¼")
                        gpu_available = False
                except:
                    gpu_available = False
            
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºPILå›¾åƒ
            image = Image.open(io.BytesIO(image_bytes))
            
            # å›¾åƒæ ¼å¼æ£€æŸ¥å’Œä¿®å¤
            if image.mode not in ['RGB', 'L']:
                if image.mode == 'RGBA':
                    # å¤„ç†é€æ˜é€šé“ - åˆ›å»ºç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', image.size, (255, 255, 255))
                    background.paste(image, mask=image.split()[-1])
                    image = background
                    if log_callback:
                        log_callback(f"      ğŸ”§ è½¬æ¢RGBAåˆ°RGBæ ¼å¼")
                elif image.mode == 'P':
                    # å¤„ç†è°ƒè‰²æ¿æ¨¡å¼
                    image = image.convert('RGB')
                    if log_callback:
                        log_callback(f"      ğŸ”§ è½¬æ¢è°ƒè‰²æ¿åˆ°RGBæ ¼å¼")
                else:
                    image = image.convert('RGB')
                    if log_callback:
                        log_callback(f"      ğŸ”§ è½¬æ¢{image.mode}åˆ°RGBæ ¼å¼")
            
            # å›¾åƒå°ºå¯¸æ£€æŸ¥
            width, height = image.size
            if width * height > 4096 * 4096:  # è¶…å¤§å›¾åƒåˆ†å—å¤„ç†
                if log_callback:
                    log_callback(f"      ğŸ“ å›¾åƒè¿‡å¤§ ({width}x{height})ï¼Œå¯ç”¨åˆ†å—å¤„ç†")
                return self._process_large_image(image, method, log_callback, gpu_available)
            
            original_size = image.size
            if log_callback:
                log_callback(f"      åŸå§‹å°ºå¯¸: {original_size[0]}x{original_size[1]}")
            
            # æ ¹æ®æ–¹æ³•é€‰æ‹©å¤„ç†æ–¹å¼ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼Œä¼˜å…ˆä½¿ç”¨Waifu2xï¼‰
            upscaled_image = None
            max_retries = 3  # å¢åŠ é‡è¯•æ¬¡æ•°ä»¥æ”¯æŒç®—æ³•å›é€€
            
            # å®šä¹‰ç®—æ³•ä¼˜å…ˆçº§ï¼šWaifu2x > ç®€å•æ”¾å¤§
            algorithm_sequence = ["waifu2x", "simple"]  # ç»Ÿä¸€ä½¿ç”¨Waifu2x
            
            for attempt in range(min(max_retries, len(algorithm_sequence))):
                current_algorithm = algorithm_sequence[attempt]
                try:
                    if log_callback:
                        algo_name = {
                            "waifu2x": "Waifu2x (AIé«˜æ¸…åŒ–)",
                            "simple": "ä¼ ç»Ÿç®—æ³•"
                        }.get(current_algorithm, current_algorithm)
                        log_callback(f"      ğŸ”„ å°è¯•ç®—æ³• {attempt+1}/{len(algorithm_sequence)}: {algo_name}")
                    
                    if current_algorithm == "waifu2x":
                        upscaled_image = self._waifu2x_upscale(image, log_callback, gpu_available, method)
                    else:  # simple
                        upscaled_image = self._simple_upscale(image, log_callback)
                    
                    # æ£€æŸ¥è¾“å‡ºå›¾åƒæœ‰æ•ˆæ€§
                    if upscaled_image and self._validate_output_image(upscaled_image):
                        if log_callback:
                            log_callback(f"      âœ… {algo_name} å¤„ç†æˆåŠŸ")
                        break
                    else:
                        if log_callback:
                            log_callback(f"      âŒ {algo_name} è¾“å‡ºå¼‚å¸¸ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç®—æ³•...")
                        upscaled_image = None
                        
                except Exception as e:
                    if log_callback:
                        error_msg = str(e)
                        if "404" in error_msg or "Not Found" in error_msg:
                            log_callback(f"      âŒ {algo_name} æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç®—æ³•")
                        elif "CUDA" in error_msg or "GPU" in error_msg:
                            log_callback(f"      âŒ {algo_name} GPUé”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç®—æ³•")
                        else:
                            log_callback(f"      âŒ {algo_name} å¤„ç†å¤±è´¥: {error_msg[:50]}...")
                    
                    # å¦‚æœæ˜¯GPUç›¸å…³é”™è¯¯ä¸”è¿˜æœ‰é‡è¯•æœºä¼šï¼Œå°è¯•CPUæ¨¡å¼
                    if "CUDA" in str(e) and gpu_available and attempt < len(algorithm_sequence) - 1:
                        gpu_available = False
                        if log_callback:
                            log_callback(f"      ğŸ”„ æ£€æµ‹åˆ°GPUé”™è¯¯ï¼Œåç»­ç®—æ³•å°†ä½¿ç”¨CPUæ¨¡å¼")
            
            # å¦‚æœæ‰€æœ‰ç®—æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ”¾å¤§ä½œä¸ºæœ€åæ‰‹æ®µ
            if not upscaled_image:
                if log_callback:
                    log_callback(f"      ğŸš¨ æ‰€æœ‰AIç®—æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ”¾å¤§ç®—æ³•")
                    log_callback(f"      ğŸ’¡ å»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAIåº“å®‰è£…çŠ¶æ€")
                upscaled_image = self._simple_upscale(image, log_callback)
            
            if upscaled_image:
                new_size = upscaled_image.size
                if log_callback:
                    log_callback(f"      é«˜æ¸…åŒ–å: {new_size[0]}x{new_size[1]}")
                
                # è½¬æ¢å›å­—èŠ‚æ•°æ®ï¼Œä¼˜åŒ–æ ¼å¼å¤„ç†
                output_buffer = io.BytesIO()
                
                # æ™ºèƒ½æ ¼å¼é€‰æ‹©
                try:
                    if hasattr(image, 'format') and image.format == 'JPEG':
                        # åŸå›¾æ˜¯JPEGï¼Œä¿æŒJPEGæ ¼å¼
                        if upscaled_image.mode != 'RGB':
                            upscaled_image = upscaled_image.convert('RGB')
                        upscaled_image.save(output_buffer, format='JPEG', quality=95, optimize=True)
                    else:
                        # å…¶ä»–æ ¼å¼ä½¿ç”¨PNG
                        upscaled_image.save(output_buffer, format='PNG', optimize=True)
                except Exception as save_error:
                    # å¤‡é€‰æ–¹æ¡ˆï¼šå¼ºåˆ¶è½¬æ¢ä¸ºRGBå¹¶ä¿å­˜ä¸ºJPEG
                    if log_callback:
                        log_callback(f"      ğŸ”§ æ ¼å¼è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨JPEGæ ¼å¼")
                    if upscaled_image.mode != 'RGB':
                        upscaled_image = upscaled_image.convert('RGB')
                    upscaled_image.save(output_buffer, format='JPEG', quality=95)
                
                return output_buffer.getvalue()
            
            return image_bytes  # å¦‚æœå¤„ç†å¤±è´¥ï¼Œè¿”å›åŸå›¾åƒ
            
        except Exception as e:
            logger.error(f"å›¾åƒé«˜æ¸…åŒ–å¤±è´¥: {e}")
            if log_callback:
                log_callback(f"      âŒ å›¾åƒå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾åƒ: {str(e)}")
            return image_bytes
    
    def _waifu2x_upscale(self, image: Image.Image, log_callback=None, gpu_available=None, method="anime") -> Image.Image:
        """ä½¿ç”¨Waifu2xè¿›è¡Œå›¾åƒé«˜æ¸…åŒ–ï¼Œæ”¯æŒå¤šç§ä¼˜åŒ–å‚æ•°"""
        try:
            if log_callback:
                log_callback(f"        ä½¿ç”¨Waifu2xç®—æ³•å¤„ç†...")
            
            # å¯¼å…¥waifu2x-ncnn-py
            from waifu2x_ncnn_py import Waifu2x
            
            # æ£€æµ‹GPUå¯ç”¨æ€§
            if gpu_available is None:
                gpu_available = self._check_gpu_availability(log_callback)
            gpuid = 0 if gpu_available else -1
            
            if log_callback and gpu_available:
                log_callback(f"        ğŸš€ ä½¿ç”¨GPUåŠ é€Ÿå¤„ç†")
            elif log_callback:
                log_callback(f"        ğŸ’» ä½¿ç”¨CPUå¤„ç†")
            
            # å›¾åƒé¢„å¤„ç†
            processed_image = self._preprocess_image(image, method, log_callback)
            
            # æ ¹æ®æ–¹æ³•å’Œå›¾åƒç‰¹æ€§é€‰æ‹©æœ€ä¼˜å‚æ•°
            config = self._get_optimal_waifu2x_config(processed_image, method, gpu_available, log_callback)
            
            # åˆ›å»ºWaifu2xå®ä¾‹
            waifu2x = Waifu2x(
                gpuid=gpuid,
                tta_mode=config['tta_mode'],
                num_threads=config['num_threads'],
                noise=config['noise'],
                scale=config['scale'],
                tilesize=config['tilesize'],
                model=config['model']
            )
            
            if log_callback:
                log_callback(f"        ğŸ“Š é…ç½®: æ¨¡å‹={config['model']}, é™å™ª={config['noise']}, ç“¦ç‰‡={config['tilesize']}")
            
            # ä½¿ç”¨Waifu2xå¤„ç†å›¾åƒ
            upscaled_image = waifu2x.process_pil(processed_image)
            
            # åå¤„ç†å’Œè´¨é‡éªŒè¯
            final_image = self._postprocess_image(upscaled_image, processed_image, log_callback)
            
            # è´¨é‡è¯„ä¼°
            quality_score = self._evaluate_upscale_quality(processed_image, final_image, log_callback)
            if log_callback:
                log_callback(f"        âœ¨ è´¨é‡è¯„åˆ†: {quality_score:.2f}/10")
            
            return final_image
            
        except ImportError as e:
            if log_callback:
                log_callback(f"        Waifu2xåº“æœªå®‰è£…: {str(e)}ã€‚è¯·è¿è¡Œ 'pip install waifu2x-ncnn-py' å®‰è£…")
            return self._simple_upscale(image, log_callback)
        except Exception as e:
            logger.error(f"Waifu2xå¤„ç†å¤±è´¥: {e}")
            if log_callback:
                log_callback(f"        âš ï¸ Waifu2xå¤„ç†å¤±è´¥: {str(e)}")
            return self._simple_upscale(image, log_callback)
    
    def _preprocess_image(self, image: Image.Image, method: str, log_callback=None) -> Image.Image:
        """å›¾åƒé¢„å¤„ç†ï¼Œä½¿ç”¨æ’ä»¶æ¶æ„è¿›è¡Œæ¨¡å—åŒ–å¤„ç†"""
        try:
            processed_image = image.copy()
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if processed_image.mode not in ['RGB', 'RGBA']:
                if log_callback:
                    log_callback(f"        ğŸ”„ è½¬æ¢å›¾åƒæ¨¡å¼: {processed_image.mode} -> RGB")
                processed_image = processed_image.convert('RGB')
            
            # ä½¿ç”¨å›¾åƒåˆ†æå™¨åˆ†æå›¾åƒç‰¹å¾
            features = self.image_analyzer.analyze_features(processed_image)
            if log_callback:
                log_callback(f"        ğŸ” å›¾åƒåˆ†æå®Œæˆ: è¾¹ç¼˜å¯†åº¦={features['edge_density']:.3f}, å™ªå£°æ°´å¹³={features['noise_level']:.3f}")
            
            # åˆ›å»ºé¢„å¤„ç†ç®¡é“
            pipeline = ImageProcessingPipeline()
            
            # æ ¹æ®æ–¹æ³•å’Œå›¾åƒç‰¹å¾é€‰æ‹©é¢„å¤„ç†æ’ä»¶
            if method == "photo":
                # ç…§ç‰‡ç±»å‹é¢„å¤„ç†ç®¡é“
                if features['contrast'] < 0.5:  # ä½å¯¹æ¯”åº¦å›¾åƒ
                    pipeline.add_processor(self.plugin_manager.get_plugin('clahe_preprocessing'))
                if features['edge_density'] < 0.3:  # éœ€è¦é”åŒ–
                    pipeline.add_processor(self.plugin_manager.get_plugin('smart_sharpening'))
                if log_callback:
                    log_callback(f"        ğŸ“¸ åº”ç”¨ç…§ç‰‡ä¼˜åŒ–é¢„å¤„ç†ç®¡é“")
            elif method == "document":
                # æ–‡æ¡£ç±»å‹é¢„å¤„ç†ç®¡é“
                pipeline.add_processor(self.plugin_manager.get_plugin('clahe_preprocessing'))
                if features['noise_level'] > 0.1:  # é«˜å™ªå£°æ–‡æ¡£
                    pipeline.add_processor(self.plugin_manager.get_plugin('noise_reduction'))
                if log_callback:
                    log_callback(f"        ğŸ“„ åº”ç”¨æ–‡æ¡£ä¼˜åŒ–é¢„å¤„ç†ç®¡é“")
            else:
                # é»˜è®¤é¢„å¤„ç†
                if features['contrast'] < 0.4:
                    pipeline.add_processor(self.plugin_manager.get_plugin('clahe_preprocessing'))
            
            # æ‰§è¡Œé¢„å¤„ç†ç®¡é“
            processed_image = pipeline.process(processed_image)
            
            return processed_image
            
        except Exception as e:
            if log_callback:
                log_callback(f"        âš ï¸ é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾åƒ: {str(e)}")
            return image
    
    def _enhance_photo(self, image: Image.Image) -> Image.Image:
        """ç…§ç‰‡ç±»å‹å›¾åƒå¢å¼º - æ‰©å±•ç‰ˆ"""
        try:
            from PIL import ImageEnhance, ImageFilter
            import cv2
            import numpy as np
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œé«˜çº§å¤„ç†
            img_array = np.array(image)
            
            # 1. CLAHEè‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ˆä»…å¯¹äº®åº¦é€šé“ï¼‰
            if len(img_array.shape) == 3:
                # è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´
                lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                lab[:,:,0] = clahe.apply(lab[:,:,0])  # åªå¯¹Lé€šé“åº”ç”¨CLAHE
                img_array = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
                enhanced = Image.fromarray(img_array)
            else:
                # ç°åº¦å›¾åƒç›´æ¥åº”ç”¨CLAHE
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                img_array = clahe.apply(img_array)
                enhanced = Image.fromarray(img_array)
            
            # 2. æ™ºèƒ½é”åŒ–ï¼ˆåŸºäºå›¾åƒå†…å®¹è‡ªé€‚åº”ï¼‰
            enhanced = self._apply_smart_sharpening(enhanced, strength=1.1)
            
            # 3. è½»å¾®å¯¹æ¯”åº¦å¢å¼º
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.05)
            
            # 4. è‰²å½©é¥±å’Œåº¦å¾®è°ƒ
            enhancer = ImageEnhance.Color(enhanced)
            enhanced = enhancer.enhance(1.02)
            
            return enhanced
        except Exception as e:
            # å¦‚æœé«˜çº§å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€å¢å¼º
            try:
                from PIL import ImageEnhance
                enhancer = ImageEnhance.Sharpness(image)
                enhanced = enhancer.enhance(1.1)
                enhancer = ImageEnhance.Contrast(enhanced)
                enhanced = enhancer.enhance(1.05)
                return enhanced
            except:
                return image
    
    def _enhance_document(self, image: Image.Image) -> Image.Image:
        """æ–‡æ¡£ç±»å‹å›¾åƒå¢å¼º - æ‰©å±•ç‰ˆ"""
        try:
            from PIL import ImageEnhance, ImageFilter, ImageOps
            import cv2
            import numpy as np
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            img_array = np.array(image)
            
            # 1. æ–‡æ¡£ä¸“ç”¨CLAHEï¼ˆæ›´å¼ºçš„å¯¹æ¯”åº¦å¢å¼ºï¼‰
            if len(img_array.shape) == 3:
                # è½¬æ¢ä¸ºç°åº¦è¿›è¡Œæ–‡æ¡£å¤„ç†
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(16,16))
                enhanced_gray = clahe.apply(gray)
                # è½¬å›RGB
                enhanced = Image.fromarray(cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2RGB))
            else:
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(16,16))
                enhanced_gray = clahe.apply(img_array)
                enhanced = Image.fromarray(enhanced_gray)
            
            # 2. æ–‡æ¡£å»å™ªï¼ˆåŒè¾¹æ»¤æ³¢ï¼‰
            img_array = np.array(enhanced)
            if len(img_array.shape) == 3:
                denoised = cv2.bilateralFilter(img_array, 9, 75, 75)
                enhanced = Image.fromarray(denoised)
            
            # 3. æ™ºèƒ½é”åŒ–ï¼ˆæ–‡æ¡£ä¸“ç”¨å¼ºåº¦ï¼‰
            enhanced = self._apply_smart_sharpening(enhanced, strength=1.4)
            
            # 4. å¼ºåŒ–å¯¹æ¯”åº¦
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.3)
            
            # 5. æ–‡æ¡£ä¸“ç”¨è¾¹ç¼˜å¢å¼º
            enhanced = enhanced.filter(ImageFilter.UnsharpMask(radius=1, percent=120, threshold=3))
            
            return enhanced
        except Exception as e:
            # å›é€€åˆ°åŸºç¡€å¢å¼º
            try:
                from PIL import ImageEnhance
                enhancer = ImageEnhance.Contrast(image)
                enhanced = enhancer.enhance(1.2)
                enhancer = ImageEnhance.Sharpness(enhanced)
                enhanced = enhancer.enhance(1.3)
                return enhanced
            except:
                return image
    
    def _apply_smart_sharpening(self, image: Image.Image, strength: float = 1.2) -> Image.Image:
        """æ™ºèƒ½é”åŒ–ç®—æ³• - åŸºäºå›¾åƒå†…å®¹è‡ªé€‚åº”è°ƒæ•´"""
        try:
            from PIL import ImageFilter, ImageEnhance
            import cv2
            import numpy as np
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„åˆ†æå›¾åƒç‰¹å¾
            img_array = np.array(image)
            
            # è®¡ç®—å›¾åƒçš„è¾¹ç¼˜å¯†åº¦å’Œå™ªç‚¹æ°´å¹³
            if len(img_array.shape) == 3:
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                gray = img_array
            
            # 1. è¾¹ç¼˜æ£€æµ‹è¯„ä¼°
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
            
            # 2. å™ªç‚¹æ°´å¹³è¯„ä¼°ï¼ˆä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­ï¼‰
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            # 3. æ ¹æ®å›¾åƒç‰¹å¾è‡ªé€‚åº”è°ƒæ•´é”åŒ–å‚æ•°
            if edge_density > 0.1:  # é«˜è¾¹ç¼˜å¯†åº¦ï¼ˆå¦‚æ–‡æ¡£ã€çº¿æ¡å›¾ï¼‰
                # ä½¿ç”¨UnsharpMaskè¿›è¡Œç²¾ç¡®é”åŒ–
                radius = 1.0
                percent = int(strength * 100)
                threshold = 2
            elif laplacian_var < 100:  # ä½å¯¹æ¯”åº¦å›¾åƒ
                # æ¸©å’Œé”åŒ–é¿å…å™ªç‚¹æ”¾å¤§
                radius = 0.5
                percent = int(strength * 80)
                threshold = 5
            else:  # æ™®é€šå›¾åƒ
                radius = 1.5
                percent = int(strength * 90)
                threshold = 3
            
            # åº”ç”¨UnsharpMaské”åŒ–
            sharpened = image.filter(ImageFilter.UnsharpMask(
                radius=radius, 
                percent=percent, 
                threshold=threshold
            ))
            
            # 4. å¤šå°ºåº¦é”åŒ–ï¼ˆé’ˆå¯¹ä¸åŒé¢‘ç‡çš„ç»†èŠ‚ï¼‰
            if strength > 1.3:  # å¼ºé”åŒ–æ¨¡å¼
                # æ·»åŠ é«˜é¢‘ç»†èŠ‚å¢å¼º
                enhancer = ImageEnhance.Sharpness(sharpened)
                sharpened = enhancer.enhance(1.1)
            
            return sharpened
            
        except Exception as e:
            # å›é€€åˆ°åŸºç¡€é”åŒ–
            try:
                from PIL import ImageEnhance
                enhancer = ImageEnhance.Sharpness(image)
                return enhancer.enhance(strength)
            except:
                return image
    
    def _get_optimal_waifu2x_config(self, image: Image.Image, method: str, gpu_available: bool, log_callback=None) -> dict:
        """æ ¹æ®å›¾åƒç‰¹æ€§å’Œæ–¹æ³•é€‰æ‹©æœ€ä¼˜Waifu2xé…ç½® - ä½¿ç”¨é…ç½®ç®¡ç†å™¨"""
        width, height = image.size
        pixel_count = width * height
        
        # ä½¿ç”¨å›¾åƒåˆ†æå™¨åˆ†æå›¾åƒç‰¹å¾
        image_features = self.image_analyzer.analyze_features(image)
        
        # ä»é…ç½®ç®¡ç†å™¨è·å–åŸºç¡€é…ç½®
        waifu2x_config = self.config.waifu2x
        
        # åŸºç¡€é…ç½®
        config = {
            'tta_mode': waifu2x_config.tta_mode,
            'num_threads': waifu2x_config.cpu_threads if not gpu_available else waifu2x_config.gpu_threads,
            'scale': waifu2x_config.scale
        }
        
        # æ™ºèƒ½ç“¦ç‰‡å¤§å°é€‰æ‹©ï¼ˆåŸºäºGPUå†…å­˜å’Œå›¾åƒå¤æ‚åº¦ï¼‰
        complexity_factor = image_features.get('complexity', 0.5)
        
        if gpu_available:
            # GPUå¤„ç† - æ ¹æ®å›¾åƒå¤§å°å’Œå¤æ‚åº¦åŠ¨æ€è°ƒæ•´
            if pixel_count > 4000000:  # è¶…å¤§å›¾åƒ
                config['tilesize'] = max(waifu2x_config.min_tilesize, 
                                       int(waifu2x_config.gpu_tilesize_large * (1 - complexity_factor * 0.3)))
            elif pixel_count > 2000000:  # å¤§å›¾åƒ
                config['tilesize'] = max(waifu2x_config.min_tilesize, 
                                       int(waifu2x_config.gpu_tilesize_medium * (1 - complexity_factor * 0.2)))
            elif pixel_count > 1000000:  # ä¸­ç­‰å›¾åƒ
                config['tilesize'] = max(waifu2x_config.min_tilesize, 
                                       int(waifu2x_config.gpu_tilesize_small * (1 - complexity_factor * 0.1)))
            else:  # å°å›¾åƒ
                config['tilesize'] = waifu2x_config.gpu_tilesize_small
        else:
            # CPUå¤„ç† - ä½¿ç”¨é…ç½®çš„CPUç“¦ç‰‡å¤§å°
            if pixel_count > 2000000:
                config['tilesize'] = waifu2x_config.cpu_tilesize_large
            elif pixel_count > 1000000:
                config['tilesize'] = waifu2x_config.cpu_tilesize_medium
            else:
                config['tilesize'] = waifu2x_config.cpu_tilesize_small
        
        # æ™ºèƒ½æ¨¡å‹å’Œå‚æ•°é€‰æ‹©
        noise_level = image_features.get('noise_level', 1)
        edge_density = image_features.get('edge_density', 0.05)
        
        if method == "anime":
            config['model'] = waifu2x_config.anime_model
            # åŠ¨æ¼«å›¾åƒæ ¹æ®è¾¹ç¼˜å¯†åº¦è°ƒæ•´é™å™ª
            if edge_density > 0.15:  # é«˜ç»†èŠ‚åŠ¨æ¼«
                config['noise'] = max(1, min(3, int(noise_level * 3) + 1))
            else:
                config['noise'] = max(2, min(3, int(noise_level * 3) + 2))
        elif method == "photo":
            config['model'] = waifu2x_config.photo_model
            # ç…§ç‰‡æ ¹æ®å™ªç‚¹æ°´å¹³æ™ºèƒ½è°ƒæ•´
            config['noise'] = max(0, min(3, int(noise_level * 3)))
        elif method == "document":
            config['model'] = waifu2x_config.document_model
            # æ–‡æ¡£é€šå¸¸éœ€è¦å¼ºé™å™ªä½†ä¿æŒæ–‡å­—æ¸…æ™°
            config['noise'] = 3 if noise_level > 0.33 else 2
        else:
            config['model'] = waifu2x_config.anime_model  # é»˜è®¤ä½¿ç”¨åŠ¨æ¼«æ¨¡å‹
            config['noise'] = max(1, min(3, noise_level))
        
        # é«˜è´¨é‡æ¨¡å¼æ¡ä»¶ä¼˜åŒ–
        enable_tta = False
        if gpu_available:
            # æ›´æ™ºèƒ½çš„TTAå¯ç”¨æ¡ä»¶
            if pixel_count < 800000:  # ä¸­å°å›¾åƒ
                if image_features.get('is_important', False):  # é‡è¦å›¾åƒ
                    enable_tta = True
                elif edge_density > 0.1 and pixel_count < 400000:  # é«˜ç»†èŠ‚å°å›¾
                    enable_tta = True
        
        config['tta_mode'] = enable_tta
        
        # åŠ¨æ€ç¼©æ”¾æ¯”ä¾‹é€‰æ‹©
        if pixel_count < 100000:  # æå°å›¾åƒå¯ä»¥ä½¿ç”¨æ›´é«˜ç¼©æ”¾
            config['scale'] = 4 if gpu_available else 2
        elif pixel_count > 8000000:  # æå¤§å›¾åƒä½¿ç”¨ä¿å®ˆç¼©æ”¾
            config['scale'] = 2
        
        # æ—¥å¿—è¾“å‡ºä¼˜åŒ–ä¿¡æ¯
        if log_callback:
            if enable_tta:
                log_callback(f"        ğŸ¯ å¯ç”¨é«˜è´¨é‡æ¨¡å¼ï¼ˆTTAï¼‰")
            log_callback(f"        âš™ï¸ ç“¦ç‰‡å¤§å°: {config['tilesize']}, é™å™ª: {config['noise']}, ç¼©æ”¾: {config['scale']}x")
            if image_features.get('complexity', 0) > 0.7:
                log_callback(f"        ğŸ” æ£€æµ‹åˆ°é«˜å¤æ‚åº¦å›¾åƒï¼Œä¼˜åŒ–å¤„ç†å‚æ•°")
        
        return config
    
    # æ³¨æ„ï¼šåŸæœ‰çš„ _analyze_image_features æ–¹æ³•å·²è¢« ImageAnalyzer ç±»æ›¿ä»£
        # æ–°çš„å›¾åƒåˆ†æåŠŸèƒ½é€šè¿‡ self.image_analyzer.analyze_features() è°ƒç”¨
    
    def _postprocess_image(self, upscaled_image: Image.Image, original_image: Image.Image, log_callback=None) -> Image.Image:
        """åå¤„ç†ä¼˜åŒ– - ä½¿ç”¨æ’ä»¶æ¶æ„è¿›è¡Œæ¨¡å—åŒ–å¤„ç†"""
        try:
            # åˆ†æåŸå›¾å’Œæ”¾å¤§å›¾ç‰¹å¾
            original_features = self.image_analyzer.analyze_features(original_image)
            upscaled_features = self.image_analyzer.analyze_features(upscaled_image)
            
            enhanced = upscaled_image
            
            # 1. è‰²å½©æ¨¡å¼å¤„ç†
            if original_image.mode == 'RGBA' and enhanced.mode == 'RGB':
                enhanced = enhanced.convert('RGBA')
            elif original_image.mode == 'L' and enhanced.mode == 'RGB':
                # å¦‚æœåŸå›¾æ˜¯ç°åº¦ï¼Œå¯é€‰æ‹©ä¿æŒç°åº¦æˆ–è½¬æ¢ä¸ºå½©è‰²
                pass  # ä¿æŒRGBä»¥è·å¾—æ›´å¥½çš„æ˜¾ç¤ºæ•ˆæœ
            
            # åˆ›å»ºåå¤„ç†ç®¡é“
            pipeline = ImageProcessingPipeline()
            
            # 2. æ ¹æ®é…ç½®å’Œå›¾åƒç‰¹å¾é€‰æ‹©åå¤„ç†æ’ä»¶
            config = self.config.postprocessing
            
            # æ™ºèƒ½è‰²å½©æ ¡æ­£
            if (config.color_enhancement.enabled and 
                original_features.get('color_richness', 0) > config.color_enhancement.min_color_richness):
                pipeline.add_processor(self.plugin_manager.get_plugin('color_enhancement'))
                if log_callback:
                    log_callback(f"        ğŸ¨ æ·»åŠ æ™ºèƒ½è‰²å½©å¢å¼º")
            
            # å™ªç‚¹æŠ‘åˆ¶ï¼ˆæ£€æµ‹å™ªç‚¹å¢åŠ ï¼‰
            noise_increased = (upscaled_features.get('noise_level', 0) > 
                             original_features.get('noise_level', 0) * 1.2)
            if config.noise_reduction.enabled and noise_increased:
                pipeline.add_processor(self.plugin_manager.get_plugin('noise_reduction'))
                if log_callback:
                    log_callback(f"        ğŸ”‡ æ·»åŠ å™ªç‚¹æŠ‘åˆ¶")
            
            # æ‰§è¡Œåå¤„ç†ç®¡é“
            if pipeline.processors:
                enhanced = pipeline.process(enhanced)
                if log_callback:
                    log_callback(f"        âœ… åå¤„ç†ç®¡é“æ‰§è¡Œå®Œæˆï¼Œå…±{len(pipeline.processors)}ä¸ªæ­¥éª¤")
            
            # æœ€ç»ˆè´¨é‡éªŒè¯
            quality_score = self.image_analyzer.calculate_quality_score(enhanced)
            if log_callback:
                log_callback(f"        ğŸ“Š æœ€ç»ˆè´¨é‡è¯„åˆ†: {quality_score:.3f}")
            
            return enhanced
            
        except Exception as e:
            if log_callback:
                log_callback(f"        âš ï¸ é«˜çº§åå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†: {str(e)}")
            # å›é€€åˆ°åŸºç¡€åå¤„ç†
            try:
                if original_image.mode == 'RGBA' and upscaled_image.mode == 'RGB':
                    return upscaled_image.convert('RGBA')
                return upscaled_image
            except:
                return upscaled_image
    
    def _apply_color_enhancement(self, image: Image.Image, features: dict) -> Image.Image:
        """æ™ºèƒ½è‰²å½©å¢å¼º"""
        try:
            from PIL import ImageEnhance
            import cv2
            import numpy as np
            
            enhanced = image.copy()
            color_richness = features.get('color_richness', 0)
            
            # 1. è‡ªé€‚åº”é¥±å’Œåº¦å¢å¼º
            if color_richness > 0.5:
                # é«˜è‰²å½©ä¸°å¯Œåº¦ï¼šè½»å¾®å¢å¼º
                saturation_factor = 1.05 + (color_richness - 0.5) * 0.1
            else:
                # ä½è‰²å½©ä¸°å¯Œåº¦ï¼šé€‚åº¦å¢å¼º
                saturation_factor = 1.1 + (0.5 - color_richness) * 0.2
            
            enhancer = ImageEnhance.Color(enhanced)
            enhanced = enhancer.enhance(min(saturation_factor, 1.3))
            
            # 2. æ™ºèƒ½ç™½å¹³è¡¡æ ¡æ­£
            if enhanced.mode in ['RGB', 'RGBA']:
                enhanced = self._apply_white_balance(enhanced)
            
            # 3. è‰²è°ƒæ˜ å°„ä¼˜åŒ–
            if color_richness > 0.4:
                enhanced = self._apply_tone_mapping(enhanced)
            
            return enhanced
            
        except Exception:
            return image
    
    def _apply_white_balance(self, image: Image.Image) -> Image.Image:
        """è‡ªåŠ¨ç™½å¹³è¡¡æ ¡æ­£"""
        try:
            import cv2
            import numpy as np
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            img_array = np.array(image)
            if len(img_array.shape) == 3 and img_array.shape[2] >= 3:
                # è®¡ç®—å„é€šé“å¹³å‡å€¼
                avg_b = np.mean(img_array[:, :, 2])  # PILä¸­æ˜¯RGBï¼Œæ‰€ä»¥Bæ˜¯ç´¢å¼•2
                avg_g = np.mean(img_array[:, :, 1])
                avg_r = np.mean(img_array[:, :, 0])
                
                # è®¡ç®—ç°åº¦ä¸–ç•Œå‡è®¾ä¸‹çš„æ ¡æ­£å› å­
                avg_gray = (avg_r + avg_g + avg_b) / 3
                
                if avg_gray > 0:
                    scale_r = avg_gray / avg_r if avg_r > 0 else 1.0
                    scale_g = avg_gray / avg_g if avg_g > 0 else 1.0
                    scale_b = avg_gray / avg_b if avg_b > 0 else 1.0
                    
                    # é™åˆ¶æ ¡æ­£å¹…åº¦
                    scale_r = np.clip(scale_r, 0.8, 1.2)
                    scale_g = np.clip(scale_g, 0.8, 1.2)
                    scale_b = np.clip(scale_b, 0.8, 1.2)
                    
                    # åº”ç”¨æ ¡æ­£
                    img_array[:, :, 0] = np.clip(img_array[:, :, 0] * scale_r, 0, 255)
                    img_array[:, :, 1] = np.clip(img_array[:, :, 1] * scale_g, 0, 255)
                    img_array[:, :, 2] = np.clip(img_array[:, :, 2] * scale_b, 0, 255)
                    
                    return Image.fromarray(img_array.astype(np.uint8), mode=image.mode)
            
            return image
            
        except Exception:
            return image
    
    def _apply_tone_mapping(self, image: Image.Image) -> Image.Image:
        """è‰²è°ƒæ˜ å°„ä¼˜åŒ–"""
        try:
            import cv2
            import numpy as np
            
            img_array = np.array(image)
            if len(img_array.shape) == 3 and img_array.shape[2] >= 3:
                # è½¬æ¢ä¸ºLABè‰²å½©ç©ºé—´è¿›è¡Œå¤„ç†
                lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
                l, a, b = cv2.split(lab)
                
                # å¯¹Lé€šé“åº”ç”¨è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
                clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))
                l = clahe.apply(l)
                
                # é‡æ–°åˆå¹¶å¹¶è½¬æ¢å›RGB
                lab = cv2.merge([l, a, b])
                rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
                
                return Image.fromarray(rgb, mode=image.mode)
            
            return image
            
        except Exception:
            return image
    
    def _apply_detail_enhancement(self, image: Image.Image, features: dict) -> Image.Image:
        """ç»†èŠ‚å¢å¼ºåå¤„ç†"""
        try:
            from PIL import ImageFilter, ImageEnhance
            import cv2
            import numpy as np
            
            enhanced = image.copy()
            edge_density = features.get('edge_density', 0)
            
            # 1. è‡ªé€‚åº”é”åŒ–
            if edge_density > 0.15:
                # é«˜è¾¹ç¼˜å¯†åº¦ï¼šè½»å¾®é”åŒ–
                sharpness_factor = 1.1
            elif edge_density > 0.08:
                # ä¸­ç­‰è¾¹ç¼˜å¯†åº¦ï¼šé€‚åº¦é”åŒ–
                sharpness_factor = 1.2
            else:
                # ä½è¾¹ç¼˜å¯†åº¦ï¼šè¾ƒå¼ºé”åŒ–
                sharpness_factor = 1.3
            
            enhancer = ImageEnhance.Sharpness(enhanced)
            enhanced = enhancer.enhance(sharpness_factor)
            
            # 2. è¾¹ç¼˜ä¿æŠ¤çš„ç»†èŠ‚å¢å¼º
            if edge_density > 0.1:
                enhanced = self._apply_edge_preserving_enhancement(enhanced)
            
            # 3. é«˜é¢‘ç»†èŠ‚å¢å¼º
            enhanced = self._apply_high_frequency_enhancement(enhanced, edge_density)
            
            return enhanced
            
        except Exception:
            return image
    
    def _apply_edge_preserving_enhancement(self, image: Image.Image) -> Image.Image:
        """è¾¹ç¼˜ä¿æŠ¤çš„ç»†èŠ‚å¢å¼º"""
        try:
            import cv2
            import numpy as np
            
            img_array = np.array(image)
            if len(img_array.shape) == 3:
                # ä½¿ç”¨åŒè¾¹æ»¤æ³¢ä¿æŠ¤è¾¹ç¼˜çš„åŒæ—¶å¢å¼ºç»†èŠ‚
                enhanced = cv2.bilateralFilter(img_array, 9, 75, 75)
                
                # è®¡ç®—ç»†èŠ‚å±‚
                detail = img_array.astype(np.float32) - enhanced.astype(np.float32)
                
                # å¢å¼ºç»†èŠ‚å±‚
                enhanced_detail = detail * 1.2
                
                # åˆå¹¶
                result = enhanced.astype(np.float32) + enhanced_detail
                result = np.clip(result, 0, 255).astype(np.uint8)
                
                return Image.fromarray(result, mode=image.mode)
            
            return image
            
        except Exception:
            return image
    
    def _apply_high_frequency_enhancement(self, image: Image.Image, edge_density: float) -> Image.Image:
        """é«˜é¢‘ç»†èŠ‚å¢å¼º"""
        try:
            import cv2
            import numpy as np
            
            img_array = np.array(image)
            if len(img_array.shape) == 3:
                # è½¬æ¢ä¸ºç°åº¦è¿›è¡Œé«˜é¢‘åˆ†æ
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
                
                # é«˜æ–¯æ¨¡ç³Šè·å–ä½é¢‘
                low_freq = cv2.GaussianBlur(gray, (5, 5), 1.0)
                
                # è®¡ç®—é«˜é¢‘
                high_freq = gray.astype(np.float32) - low_freq.astype(np.float32)
                
                # æ ¹æ®è¾¹ç¼˜å¯†åº¦è°ƒæ•´å¢å¼ºå¼ºåº¦
                enhancement_factor = 0.3 if edge_density > 0.15 else 0.5
                
                # å¢å¼ºé«˜é¢‘
                enhanced_high_freq = high_freq * enhancement_factor
                
                # åº”ç”¨åˆ°åŸå›¾çš„æ¯ä¸ªé€šé“
                result = img_array.copy().astype(np.float32)
                for i in range(3):
                    result[:, :, i] += enhanced_high_freq
                
                result = np.clip(result, 0, 255).astype(np.uint8)
                return Image.fromarray(result, mode=image.mode)
            
            return image
            
        except Exception:
            return image
    
    def _detect_noise_increase(self, original: Image.Image, upscaled: Image.Image) -> bool:
        """æ£€æµ‹æ”¾å¤§è¿‡ç¨‹ä¸­æ˜¯å¦äº§ç”Ÿäº†å™ªç‚¹å¢åŠ """
        try:
            import cv2
            import numpy as np
            
            # å°†å›¾åƒè°ƒæ•´åˆ°ç›¸åŒå°ºå¯¸è¿›è¡Œæ¯”è¾ƒ
            original_resized = original.resize(upscaled.size, Image.Resampling.LANCZOS)
            
            # è½¬æ¢ä¸ºç°åº¦
            orig_gray = np.array(original_resized.convert('L'))
            upsc_gray = np.array(upscaled.convert('L'))
            
            # è®¡ç®—å™ªç‚¹æ°´å¹³ï¼ˆä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
            orig_noise = cv2.Laplacian(orig_gray, cv2.CV_64F).var()
            upsc_noise = cv2.Laplacian(upsc_gray, cv2.CV_64F).var()
            
            # å¦‚æœæ”¾å¤§åå™ªç‚¹æ˜¾è‘—å¢åŠ ï¼Œè¿”å›True
            noise_increase_ratio = upsc_noise / (orig_noise + 1e-6)
            return noise_increase_ratio > 1.3
            
        except Exception:
            return False
    
    def _apply_noise_reduction(self, image: Image.Image, features: dict) -> Image.Image:
        """æ™ºèƒ½å™ªç‚¹æŠ‘åˆ¶"""
        try:
            import cv2
            import numpy as np
            
            img_array = np.array(image)
            if len(img_array.shape) == 3:
                # ä½¿ç”¨éå±€éƒ¨å‡å€¼å»å™ª
                denoised = cv2.fastNlMeansDenoisingColored(img_array, None, 6, 6, 7, 21)
                
                # ä¿æŒè¾¹ç¼˜é”åº¦
                edge_density = features.get('edge_density', 0)
                if edge_density > 0.1:
                    # é«˜è¾¹ç¼˜å¯†åº¦æ—¶ï¼Œæ··åˆåŸå›¾ä»¥ä¿æŒç»†èŠ‚
                    alpha = 0.7  # å»å™ªå›¾åƒæƒé‡
                    result = (alpha * denoised + (1 - alpha) * img_array).astype(np.uint8)
                else:
                    result = denoised
                
                return Image.fromarray(result, mode=image.mode)
            
            return image
            
        except Exception:
            return image
    
    def _apply_tone_adjustment(self, image: Image.Image, features: dict) -> Image.Image:
        """è‰²è°ƒå’Œäº®åº¦å¾®è°ƒ"""
        try:
            from PIL import ImageEnhance
            import cv2
            import numpy as np
            
            enhanced = image.copy()
            
            # 1. è‡ªé€‚åº”å¯¹æ¯”åº¦è°ƒæ•´
            img_array = np.array(enhanced.convert('L'))
            mean_brightness = np.mean(img_array)
            
            if mean_brightness < 100:  # åæš—å›¾åƒ
                # è½»å¾®æå‡äº®åº¦å’Œå¯¹æ¯”åº¦
                brightness_enhancer = ImageEnhance.Brightness(enhanced)
                enhanced = brightness_enhancer.enhance(1.05)
                
                contrast_enhancer = ImageEnhance.Contrast(enhanced)
                enhanced = contrast_enhancer.enhance(1.1)
                
            elif mean_brightness > 180:  # åäº®å›¾åƒ
                # è½»å¾®é™ä½äº®åº¦ï¼Œå¢åŠ å¯¹æ¯”åº¦
                brightness_enhancer = ImageEnhance.Brightness(enhanced)
                enhanced = brightness_enhancer.enhance(0.98)
                
                contrast_enhancer = ImageEnhance.Contrast(enhanced)
                enhanced = contrast_enhancer.enhance(1.05)
            
            else:  # æ­£å¸¸äº®åº¦
                # è½»å¾®å¢å¼ºå¯¹æ¯”åº¦
                contrast_enhancer = ImageEnhance.Contrast(enhanced)
                enhanced = contrast_enhancer.enhance(1.03)
            
            # 2. ä¼½é©¬æ ¡æ­£ï¼ˆå¯é€‰ï¼‰
            if features.get('complexity', 0) > 0.5:
                enhanced = self._apply_gamma_correction(enhanced, mean_brightness)
            
            return enhanced
            
        except Exception:
            return image
    
    def _apply_gamma_correction(self, image: Image.Image, mean_brightness: float) -> Image.Image:
        """è‡ªé€‚åº”ä¼½é©¬æ ¡æ­£"""
        try:
            import numpy as np
            
            # æ ¹æ®å¹³å‡äº®åº¦ç¡®å®šä¼½é©¬å€¼
            if mean_brightness < 100:
                gamma = 0.9  # æäº®æš—éƒ¨
            elif mean_brightness > 180:
                gamma = 1.1  # å‹æš—äº®éƒ¨
            else:
                gamma = 1.0  # æ— éœ€è°ƒæ•´
            
            if gamma != 1.0:
                img_array = np.array(image).astype(np.float32) / 255.0
                corrected = np.power(img_array, gamma)
                corrected = (corrected * 255).astype(np.uint8)
                return Image.fromarray(corrected, mode=image.mode)
            
            return image
            
        except Exception:
            return image
    
    def _final_quality_check(self, enhanced: Image.Image, original: Image.Image, log_callback=None) -> Image.Image:
        """æœ€ç»ˆè´¨é‡éªŒè¯å’Œä¿®æ­£"""
        try:
            # 1. å°ºå¯¸éªŒè¯
            if enhanced.size != original.size and hasattr(self, 'target_scale'):
                expected_size = (int(original.size[0] * self.target_scale), 
                               int(original.size[1] * self.target_scale))
                if enhanced.size != expected_size:
                    if log_callback:
                        log_callback(f"        ğŸ“ ä¿®æ­£è¾“å‡ºå°ºå¯¸: {enhanced.size} -> {expected_size}")
                    enhanced = enhanced.resize(expected_size, Image.Resampling.LANCZOS)
            
            # 2. è‰²å½©æ¨¡å¼éªŒè¯
            if enhanced.mode != original.mode and original.mode in ['RGB', 'RGBA', 'L']:
                if log_callback:
                    log_callback(f"        ğŸ¨ ä¿®æ­£è‰²å½©æ¨¡å¼: {enhanced.mode} -> {original.mode}")
                enhanced = enhanced.convert(original.mode)
            
            # 3. è´¨é‡è¯„ä¼°
            quality_score = self._evaluate_quality(enhanced)
            if log_callback:
                log_callback(f"        ğŸ“Š æœ€ç»ˆè´¨é‡è¯„åˆ†: {quality_score:.3f}")
            
            return enhanced
            
        except Exception as e:
            if log_callback:
                log_callback(f"        âš ï¸ è´¨é‡æ£€æŸ¥å¤±è´¥: {str(e)}")
            return enhanced
    
    def _evaluate_quality(self, image: Image.Image) -> float:
        """è¯„ä¼°å•å¼ å›¾åƒè´¨é‡"""
        try:
            import numpy as np
            import cv2
            
            img_array = np.array(image)
            if len(img_array.shape) == 3:
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                gray = img_array
            
            scores = []
            
            # 1. è¾¹ç¼˜æ¸…æ™°åº¦è¯„åˆ† (0-10)
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / edges.size
            edge_score = min(10.0, edge_density * 50)  # å½’ä¸€åŒ–åˆ°0-10
            scores.append(edge_score)
            
            # 2. å¯¹æ¯”åº¦è¯„åˆ† (0-10)
            contrast = gray.std()
            contrast_score = min(10.0, contrast / 25.5)  # å½’ä¸€åŒ–åˆ°0-10
            scores.append(contrast_score)
            
            # 3. ç»†èŠ‚ä¸°å¯Œåº¦è¯„åˆ† (0-10)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            detail_score = min(10.0, laplacian_var / 500)  # å½’ä¸€åŒ–åˆ°0-10
            scores.append(detail_score)
            
            # 4. å™ªç‚¹æ§åˆ¶è¯„åˆ† (0-10ï¼Œå™ªç‚¹è¶Šå°‘åˆ†æ•°è¶Šé«˜)
            # ä½¿ç”¨é«˜é¢‘å™ªç‚¹æ£€æµ‹
            kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])
            noise_response = cv2.filter2D(gray, -1, kernel)
            noise_level = np.std(noise_response)
            noise_score = max(0.0, 10.0 - noise_level / 10)  # å™ªç‚¹è¶Šå°‘åˆ†æ•°è¶Šé«˜
            scores.append(noise_score)
            
            # ç»¼åˆè¯„åˆ†
            final_score = np.mean(scores)
            return min(10.0, max(0.0, final_score))
            
        except Exception:
            return 5.0  # é»˜è®¤ä¸­ç­‰è¯„åˆ†
    
    def _evaluate_upscale_quality(self, original: Image.Image, upscaled: Image.Image, log_callback=None) -> float:
        """è¯„ä¼°é«˜æ¸…åŒ–è´¨é‡"""
        try:
            import numpy as np
            
            # å°†åŸå›¾æ”¾å¤§åˆ°ç›¸åŒå°ºå¯¸è¿›è¡Œæ¯”è¾ƒ
            original_resized = original.resize(upscaled.size, Image.LANCZOS)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            orig_array = np.array(original_resized)
            upsc_array = np.array(upscaled)
            
            # è®¡ç®—å¤šä¸ªè´¨é‡æŒ‡æ ‡
            scores = []
            
            # 1. è¾¹ç¼˜æ¸…æ™°åº¦è¯„åˆ†
            edge_score = self._calculate_edge_sharpness(upsc_array, orig_array)
            scores.append(edge_score)
            
            # 2. ç»†èŠ‚ä¿æŒè¯„åˆ†
            detail_score = self._calculate_detail_preservation(upsc_array, orig_array)
            scores.append(detail_score)
            
            # 3. å™ªç‚¹æ§åˆ¶è¯„åˆ†
            noise_score = self._calculate_noise_reduction(upsc_array, orig_array)
            scores.append(noise_score)
            
            # ç»¼åˆè¯„åˆ†
            final_score = np.mean(scores)
            
            return min(10.0, max(0.0, final_score))
            
        except Exception as e:
            if log_callback:
                log_callback(f"        âš ï¸ è´¨é‡è¯„ä¼°å¤±è´¥: {str(e)}")
            return 5.0  # é»˜è®¤ä¸­ç­‰è¯„åˆ†
    
    def _calculate_edge_sharpness(self, upscaled: np.ndarray, original: np.ndarray) -> float:
        """è®¡ç®—è¾¹ç¼˜æ¸…æ™°åº¦è¯„åˆ†"""
        try:
            from scipy import ndimage
            
            # è®¡ç®—æ¢¯åº¦
            if len(upscaled.shape) == 3:
                upscaled_gray = np.mean(upscaled, axis=2)
                original_gray = np.mean(original, axis=2)
            else:
                upscaled_gray = upscaled
                original_gray = original
            
            # Sobelè¾¹ç¼˜æ£€æµ‹
            upscaled_edges = ndimage.sobel(upscaled_gray)
            original_edges = ndimage.sobel(original_gray)
            
            # è®¡ç®—è¾¹ç¼˜å¼ºåº¦
            upscaled_edge_strength = np.mean(np.abs(upscaled_edges))
            original_edge_strength = np.mean(np.abs(original_edges))
            
            # è¾¹ç¼˜å¢å¼ºæ¯”ç‡
            if original_edge_strength > 0:
                edge_ratio = upscaled_edge_strength / original_edge_strength
                return min(10.0, edge_ratio * 5.0)
            else:
                return 5.0
                
        except:
            return 5.0
    
    def _calculate_detail_preservation(self, upscaled: np.ndarray, original: np.ndarray) -> float:
        """è®¡ç®—ç»†èŠ‚ä¿æŒè¯„åˆ†"""
        try:
            # è®¡ç®—æ ‡å‡†å·®ï¼ˆç»†èŠ‚ä¸°å¯Œåº¦æŒ‡æ ‡ï¼‰
            upscaled_std = np.std(upscaled)
            original_std = np.std(original)
            
            if original_std > 0:
                detail_ratio = upscaled_std / original_std
                return min(10.0, detail_ratio * 5.0)
            else:
                return 5.0
                
        except:
            return 5.0
    
    def _calculate_noise_reduction(self, upscaled: np.ndarray, original: np.ndarray) -> float:
        """è®¡ç®—å™ªç‚¹æ§åˆ¶è¯„åˆ†"""
        try:
            # ç®€å•çš„å™ªç‚¹è¯„ä¼°ï¼šè®¡ç®—é«˜é¢‘æˆåˆ†
            from scipy import ndimage
            
            if len(upscaled.shape) == 3:
                upscaled_gray = np.mean(upscaled, axis=2)
                original_gray = np.mean(original, axis=2)
            else:
                upscaled_gray = upscaled
                original_gray = original
            
            # é«˜é€šæ»¤æ³¢æ£€æµ‹å™ªç‚¹
            kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])
            upscaled_noise = np.abs(ndimage.convolve(upscaled_gray, kernel))
            original_noise = np.abs(ndimage.convolve(original_gray, kernel))
            
            upscaled_noise_level = np.mean(upscaled_noise)
            original_noise_level = np.mean(original_noise)
            
            # å™ªç‚¹å‡å°‘æ¯”ç‡
            if original_noise_level > 0:
                noise_reduction = 1.0 - (upscaled_noise_level / original_noise_level)
                return max(0.0, min(10.0, (noise_reduction + 0.5) * 10.0))
            else:
                return 7.0
                
        except:
            return 5.0
    

    
    def _simple_upscale(self, image: Image.Image, log_callback=None) -> Image.Image:
        """ç®€å•çš„å›¾åƒæ”¾å¤§"""
        try:
            if log_callback:
                log_callback(f"        ä½¿ç”¨ä¼ ç»Ÿç®—æ³•å¤„ç†...")
            
            width, height = image.size
            new_size = (width * 2, height * 2)
            return image.resize(new_size, Image.LANCZOS)
            
        except Exception as e:
            logger.error(f"ç®€å•æ”¾å¤§å¤±è´¥: {e}")
            return image
    
    def _validate_output_image(self, image: Image.Image) -> bool:
        """éªŒè¯è¾“å‡ºå›¾åƒçš„æœ‰æ•ˆæ€§"""
        try:
            if not image or image.size[0] == 0 or image.size[1] == 0:
                return False
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„æ£€æŸ¥
            import numpy as np
            img_array = np.array(image)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå…¨é»‘å›¾åƒ
            if np.all(img_array == 0):
                return False
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚å¸¸å›¾åƒï¼ˆæ ‡å‡†å·®è¿‡å°å¯èƒ½æ˜¯é›ªèŠ±çŠ¶æ€ï¼‰
            if np.std(img_array) < 5:
                return False
            
            # æ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰åˆç†çš„åƒç´ å€¼åˆ†å¸ƒ
            unique_values = len(np.unique(img_array))
            if unique_values < 10:  # é¢œè‰²è¿‡å°‘å¯èƒ½æ˜¯å¼‚å¸¸å›¾åƒ
                return False
            
            return True
            
        except Exception:
            return False
    
    def _process_large_image(self, image: Image.Image, method: str, log_callback=None, gpu_available=None) -> bytes:
        """å¤„ç†è¶…å¤§å›¾åƒçš„åˆ†å—å¤„ç†"""
        try:
            if log_callback:
                log_callback(f"      ğŸ”„ å¯åŠ¨åˆ†å—å¤„ç†æ¨¡å¼")
            
            width, height = image.size
            # è®¡ç®—åˆ†å—å¤§å°
            block_size = 2048 if gpu_available else 1024
            
            # åˆ›å»ºè¾“å‡ºå›¾åƒ
            output_width = width * 2
            output_height = height * 2
            output_image = Image.new('RGB', (output_width, output_height))
            
            # åˆ†å—å¤„ç†
            blocks_x = (width + block_size - 1) // block_size
            blocks_y = (height + block_size - 1) // block_size
            
            for y in range(blocks_y):
                for x in range(blocks_x):
                    # è®¡ç®—å—çš„è¾¹ç•Œ
                    left = x * block_size
                    top = y * block_size
                    right = min(left + block_size, width)
                    bottom = min(top + block_size, height)
                    
                    # æå–å—
                    block = image.crop((left, top, right, bottom))
                    
                    # å¤„ç†å—
                    block_bytes = io.BytesIO()
                    block.save(block_bytes, format='PNG')
                    
                    # é€’å½’è°ƒç”¨ï¼ˆä½†ä¸ä¼šå†æ¬¡è§¦å‘å¤§å›¾åƒå¤„ç†ï¼‰
                    processed_block_bytes = self._upscale_image(
                        block_bytes.getvalue(), method, None, gpu_available
                    )
                    
                    # å°†å¤„ç†åçš„å—æ”¾å›è¾“å‡ºå›¾åƒ
                    processed_block = Image.open(io.BytesIO(processed_block_bytes))
                    output_left = left * 2
                    output_top = top * 2
                    output_image.paste(processed_block, (output_left, output_top))
                    
                    if log_callback:
                        progress = ((y * blocks_x + x + 1) / (blocks_x * blocks_y)) * 100
                        log_callback(f"      ğŸ“Š åˆ†å—è¿›åº¦: {progress:.1f}%")
            
            # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
            output_buffer = io.BytesIO()
            output_image.save(output_buffer, format='PNG', optimize=True)
            return output_buffer.getvalue()
            
        except Exception as e:
            logger.error(f"å¤§å›¾åƒåˆ†å—å¤„ç†å¤±è´¥: {e}")
            if log_callback:
                log_callback(f"      âŒ åˆ†å—å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ”¾å¤§")
            # é™çº§åˆ°ç®€å•æ”¾å¤§
            simple_result = self._simple_upscale(image, log_callback)
            output_buffer = io.BytesIO()
            simple_result.save(output_buffer, format='PNG', optimize=True)
            return output_buffer.getvalue()
    
    def _replace_image_in_page(self, page, xref: int, new_image_bytes: bytes):
        """æ›¿æ¢é¡µé¢ä¸­çš„å›¾åƒ"""
        try:
            # è·å–æ–‡æ¡£å¯¹è±¡
            doc = page.parent
            
            # æ›´æ–°å›¾åƒå¯¹è±¡
            doc.update_stream(xref, new_image_bytes)
            
            # åˆ·æ–°é¡µé¢ä»¥åº”ç”¨æ›´æ”¹
            page.clean_contents()
            
        except Exception as e:
            logger.error(f"å›¾åƒæ›¿æ¢å¤±è´¥: {e}")
    
    def _get_method_description(self, method: str) -> str:
        """è·å–æ–¹æ³•æè¿°"""
        descriptions = {
            "anime": "åŠ¨æ¼«/æ’å›¾ï¼ˆWaifu2xï¼‰",
            "photo": "ç…§ç‰‡/å†™çœŸï¼ˆWaifu2xï¼‰",
            "document": "æ‰«ææ–‡æ¡£ï¼ˆWaifu2xï¼‰"
        }
        return descriptions.get(method, "é€šç”¨å¤„ç†")
    
    def _check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–é¡¹"""
        try:
            import fitz
            from PIL import Image
        except ImportError as e:
            logger.warning(f"PDFé«˜æ¸…åŒ–æ’ä»¶ä¾èµ–é¡¹ç¼ºå¤±: {e}")
    
    def _setup_gpu_environment(self):
        """è®¾ç½®GPUç¯å¢ƒï¼Œè§£å†³åŒæ˜¾å¡é—®é¢˜"""
        import os
        
        # å¼ºåˆ¶ä½¿ç”¨CUDAè®¾å¤‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
        
        # è®¾ç½®PyTorch CUDAè®¾å¤‡é¡ºåº
        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
        
        # ç¦ç”¨CPUå›é€€è­¦å‘Š
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
    
    def _check_gpu_availability(self, log_callback=None) -> bool:
        """æ£€æµ‹GPUå¯ç”¨æ€§ - å¢å¼ºåŒæ˜¾å¡æ”¯æŒ"""
        try:
            import torch
            
            # åŸºç¡€GPUæ£€æŸ¥
            if not torch.cuda.is_available():
                if log_callback:
                    log_callback("ğŸš« CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                return False
            
            device_count = torch.cuda.device_count()
            if device_count == 0:
                if log_callback:
                    log_callback("ğŸš« æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                return False
            
            # åŒæ˜¾å¡ç¯å¢ƒè¯Šæ–­
            if log_callback:
                log_callback(f"ğŸ” æ£€æµ‹åˆ° {device_count} ä¸ªGPUè®¾å¤‡:")
                for i in range(device_count):
                    try:
                        props = torch.cuda.get_device_properties(i)
                        memory_gb = props.total_memory / 1024**3
                        log_callback(f"  GPU {i}: {props.name} ({memory_gb:.1f}GB)")
                        
                        # æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨äºè®¡ç®—
                        torch.cuda.set_device(i)
                        test_tensor = torch.tensor([1.0]).cuda()
                        _ = test_tensor + 1
                        log_callback(f"  âœ… GPU {i} å¯ç”¨äºCUDAè®¡ç®—")
                    except Exception as e:
                        log_callback(f"  âŒ GPU {i} ä¸å¯ç”¨: {str(e)}")
            
            # é€‰æ‹©æœ€ä½³GPUï¼ˆä¼˜å…ˆé€‰æ‹©æ˜¾å­˜æœ€å¤§çš„ç‹¬ç«‹æ˜¾å¡ï¼‰
            best_gpu = self._select_best_gpu(log_callback)
            if best_gpu is not None:
                torch.cuda.set_device(best_gpu)
                if log_callback:
                    log_callback(f"ğŸ¯ é€‰æ‹©GPU {best_gpu}ä½œä¸ºä¸»è¦è®¡ç®—è®¾å¤‡")
                return True
            
            return False
            
        except ImportError:
            if log_callback:
                log_callback("âŒ PyTorchæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨GPUåŠ é€Ÿ")
            return False
        except Exception as e:
            if log_callback:
                log_callback(f"âŒ GPUæ£€æµ‹å¤±è´¥: {str(e)}")
            return False
    
    def _select_best_gpu(self, log_callback=None) -> int:
        """é€‰æ‹©æœ€ä½³GPUè®¾å¤‡ï¼ˆåŒæ˜¾å¡ç¯å¢ƒä¼˜åŒ–ï¼‰"""
        try:
            import torch
            device_count = torch.cuda.device_count()
            
            if device_count == 1:
                return 0
            
            best_device = 0
            max_memory = 0
            
            for i in range(device_count):
                try:
                    props = torch.cuda.get_device_properties(i)
                    memory = props.total_memory
                    
                    # ä¼˜å…ˆé€‰æ‹©ç‹¬ç«‹æ˜¾å¡ï¼ˆé€šå¸¸æ˜¾å­˜æ›´å¤§ï¼‰
                    # NVIDIAç‹¬ç«‹æ˜¾å¡é€šå¸¸åç§°åŒ…å«GTXã€RTXã€Teslaç­‰
                    is_discrete = any(keyword in props.name.upper() for keyword in 
                                    ['GTX', 'RTX', 'TESLA', 'QUADRO', 'TITAN'])
                    
                    if log_callback:
                        gpu_type = "ç‹¬ç«‹æ˜¾å¡" if is_discrete else "é›†æˆæ˜¾å¡"
                        log_callback(f"  GPU {i}: {props.name} - {gpu_type}, {memory/1024**3:.1f}GB")
                    
                    # é€‰æ‹©ç­–ç•¥ï¼šä¼˜å…ˆç‹¬ç«‹æ˜¾å¡ï¼Œå…¶æ¬¡æ˜¾å­˜å¤§çš„
                    if is_discrete and memory > max_memory:
                        best_device = i
                        max_memory = memory
                    elif not is_discrete and max_memory == 0:
                        # å¦‚æœæ²¡æœ‰ç‹¬ç«‹æ˜¾å¡ï¼Œé€‰æ‹©æ˜¾å­˜æœ€å¤§çš„é›†æˆæ˜¾å¡
                        if memory > max_memory:
                            best_device = i
                            max_memory = memory
                            
                except Exception as e:
                    if log_callback:
                        log_callback(f"  GPU {i} ä¿¡æ¯è·å–å¤±è´¥: {str(e)}")
                    continue
            
            return best_device
            
        except Exception as e:
            if log_callback:
                log_callback(f"GPUé€‰æ‹©å¤±è´¥: {str(e)}")
            return 0
    
    def _optimize_image_layout(self, original_rect, image_path, page, log_callback=None):
        """æ™ºèƒ½ä¼˜åŒ–å›¾åƒå¸ƒå±€ï¼Œè€ƒè™‘é«˜æ¸…åŒ–åçš„å®é™…å°ºå¯¸
        
        Args:
            original_rect: åŸå§‹å›¾åƒçŸ©å½¢åŒºåŸŸ
            image_path: é«˜æ¸…åŒ–åçš„å›¾åƒæ–‡ä»¶è·¯å¾„
            page: PDFé¡µé¢å¯¹è±¡
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
            
        Returns:
            ä¼˜åŒ–åçš„å›¾åƒçŸ©å½¢åŒºåŸŸ
        """
        try:
            # è·å–é¡µé¢å°ºå¯¸
            page_rect = page.rect
            page_width = page_rect.width
            page_height = page_rect.height
            
            # è·å–é«˜æ¸…åŒ–åçš„å›¾åƒå°ºå¯¸
            with Image.open(image_path) as img:
                upscaled_width, upscaled_height = img.size
                img_aspect_ratio = upscaled_width / upscaled_height
            
            # è®¡ç®—åŸå§‹å›¾åƒçš„ç†è®ºå°ºå¯¸ï¼ˆç”¨äºæ¯”è¾ƒï¼‰
            original_width = original_rect.width
            original_height = original_rect.height
            
            if log_callback:
                scale_factor_w = upscaled_width / original_width if original_width > 0 else 1
                scale_factor_h = upscaled_height / original_height if original_height > 0 else 1
                log_callback(f"        ğŸ“ å›¾åƒå·²æ”¾å¤§: {original_width:.0f}x{original_height:.0f} -> {upscaled_width}x{upscaled_height} (ç¼©æ”¾: {scale_factor_w:.1f}x)")
            
            # åˆ†æé¡µé¢å¸ƒå±€ï¼Œæ£€æµ‹å¯ç”¨ç©ºé—´
            available_space = self._analyze_page_layout(page, original_rect, log_callback)
            
            # è®¡ç®—æœ€ä½³æ˜¾ç¤ºå°ºå¯¸ï¼ˆè€ƒè™‘é«˜æ¸…åŒ–åçš„å®é™…å°ºå¯¸ï¼‰
            optimized_rect = self._calculate_display_rect(
                original_rect, upscaled_width, upscaled_height, 
                available_space, page_width, page_height, log_callback
            )
            
            if log_callback:
                orig_area = (original_rect.width * original_rect.height)
                new_area = (optimized_rect.width * optimized_rect.height)
                size_increase = ((new_area - orig_area) / orig_area) * 100
                log_callback(f"        ğŸ“ æ˜¾ç¤ºå°ºå¯¸ä¼˜åŒ–: {size_increase:.1f}% å¢å¤§")
            
            return optimized_rect
            
        except Exception as e:
            if log_callback:
                log_callback(f"        âš ï¸ å¸ƒå±€ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å°ºå¯¸: {str(e)}")
            return original_rect
    
    def _analyze_page_layout(self, page, current_rect, log_callback=None):
        """åˆ†æé¡µé¢å¸ƒå±€ï¼Œæ£€æµ‹å¯ç”¨çš„ç©ºç™½åŒºåŸŸ
        
        Args:
            page: PDFé¡µé¢å¯¹è±¡
            current_rect: å½“å‰å›¾åƒçŸ©å½¢
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
            
        Returns:
            å¯ç”¨ç©ºé—´ä¿¡æ¯å­—å…¸
        """
        page_rect = page.rect
        
        # è·å–é¡µé¢ä¸­çš„æ‰€æœ‰æ–‡æœ¬å—å’Œå›¾åƒ
        text_blocks = page.get_text("dict")["blocks"]
        image_list = page.get_images()
        
        # è®¡ç®—é¡µé¢è¾¹è·ï¼ˆåŸºäºå†…å®¹åˆ†å¸ƒï¼‰
        content_bounds = self._calculate_content_bounds(text_blocks, image_list, page)
        
        # æ£€æµ‹å½“å‰å›¾åƒå‘¨å›´çš„ç©ºç™½åŒºåŸŸ
        available_space = {
            'left_margin': max(0, current_rect.x0 - content_bounds['left']),
            'right_margin': max(0, content_bounds['right'] - current_rect.x1),
            'top_margin': max(0, current_rect.y0 - content_bounds['top']),
            'bottom_margin': max(0, content_bounds['bottom'] - current_rect.y1),
            'page_width': page_rect.width,
            'page_height': page_rect.height,
            'content_bounds': content_bounds
        }
        
        return available_space
    
    def _calculate_content_bounds(self, text_blocks, image_list, page):
        """è®¡ç®—é¡µé¢å†…å®¹çš„è¾¹ç•Œ
        
        Args:
            text_blocks: æ–‡æœ¬å—åˆ—è¡¨
            image_list: å›¾åƒåˆ—è¡¨
            page: PDFé¡µé¢å¯¹è±¡
            
        Returns:
            å†…å®¹è¾¹ç•Œå­—å…¸
        """
        page_rect = page.rect
        
        # é»˜è®¤è¾¹ç•Œï¼ˆé¡µé¢è¾¹ç¼˜ï¼‰
        bounds = {
            'left': page_rect.x0,
            'right': page_rect.x1,
            'top': page_rect.y0,
            'bottom': page_rect.y1
        }
        
        # åˆ†ææ–‡æœ¬å†…å®¹è¾¹ç•Œ
        text_rects = []
        for block in text_blocks:
            if 'lines' in block:  # æ–‡æœ¬å—
                for line in block['lines']:
                    for span in line['spans']:
                        bbox = span['bbox']
                        text_rects.append(bbox)
        
        # åˆ†æå›¾åƒè¾¹ç•Œ
        for img in image_list:
            img_rects = page.get_image_rects(img[0])
            for rect in img_rects:
                text_rects.append([rect.x0, rect.y0, rect.x1, rect.y1])
        
        # è®¡ç®—å®é™…å†…å®¹è¾¹ç•Œ
        if text_rects:
            all_x0 = [rect[0] for rect in text_rects]
            all_y0 = [rect[1] for rect in text_rects]
            all_x1 = [rect[2] for rect in text_rects]
            all_y1 = [rect[3] for rect in text_rects]
            
            content_left = min(all_x0)
            content_top = min(all_y0)
            content_right = max(all_x1)
            content_bottom = max(all_y1)
            
            # æ™ºèƒ½è¾¹è·åˆ†æï¼šæ£€æµ‹å¯ç”¨çš„ç™½ç©ºé—´
            page_width = page_rect.x1 - page_rect.x0
            page_height = page_rect.y1 - page_rect.y0
            
            # è®¡ç®—å„æ–¹å‘çš„ç©ºç™½ç©ºé—´
            left_margin = content_left - page_rect.x0
            right_margin = page_rect.x1 - content_right
            top_margin = content_top - page_rect.y0
            bottom_margin = page_rect.y1 - content_bottom
            
            # ç™½ç©ºé—´åˆ©ç”¨ç­–ç•¥ï¼šå¦‚æœæŸä¸ªæ–¹å‘æœ‰è¶³å¤Ÿç©ºé—´ï¼Œå¯ä»¥æ›´ç§¯æåœ°åˆ©ç”¨
            margin_threshold = min(page_width, page_height) * 0.05  # 5%é¡µé¢å°ºå¯¸ä½œä¸ºé˜ˆå€¼
            
            # æ›´æ–°è¾¹ç•Œï¼Œè€ƒè™‘å¯åˆ©ç”¨çš„ç™½ç©ºé—´
            if left_margin > margin_threshold:
                bounds['left'] = content_left - left_margin * 0.3  # åˆ©ç”¨30%çš„å·¦è¾¹è·
            else:
                bounds['left'] = content_left
                
            if right_margin > margin_threshold:
                bounds['right'] = content_right + right_margin * 0.3  # åˆ©ç”¨30%çš„å³è¾¹è·
            else:
                bounds['right'] = content_right
                
            if top_margin > margin_threshold:
                bounds['top'] = content_top - top_margin * 0.3  # åˆ©ç”¨30%çš„ä¸Šè¾¹è·
            else:
                bounds['top'] = content_top
                
            if bottom_margin > margin_threshold:
                bounds['bottom'] = content_bottom + bottom_margin * 0.3  # åˆ©ç”¨30%çš„ä¸‹è¾¹è·
            else:
                bounds['bottom'] = content_bottom
        
        return bounds
    
    def _calculate_display_rect(self, original_rect, upscaled_width, upscaled_height, 
                              available_space, page_width, page_height, log_callback=None):
        """è®¡ç®—é«˜æ¸…åŒ–å›¾åƒçš„æœ€ä½³æ˜¾ç¤ºçŸ©å½¢
        
        Args:
            original_rect: åŸå§‹å›¾åƒçŸ©å½¢
            upscaled_width: é«˜æ¸…åŒ–åçš„å›¾åƒå®½åº¦
            upscaled_height: é«˜æ¸…åŒ–åçš„å›¾åƒé«˜åº¦
            available_space: å¯ç”¨ç©ºé—´ä¿¡æ¯
            page_width: é¡µé¢å®½åº¦
            page_height: é¡µé¢é«˜åº¦
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
            
        Returns:
            ä¼˜åŒ–åçš„å›¾åƒçŸ©å½¢
        """
        import fitz
        
        # è®¡ç®—å›¾åƒçš„å®½é«˜æ¯”
        img_aspect_ratio = upscaled_width / upscaled_height
        
        # è®¡ç®—å¯ç”¨çš„æœ€å¤§æ˜¾ç¤ºåŒºåŸŸï¼ˆæ›´ç§¯æçš„ç©ºé—´åˆ©ç”¨ï¼‰
        max_display_width = min(
            page_width * 0.98,  # æå‡åˆ°98%é¡µé¢å®½åº¦åˆ©ç”¨ç‡
            original_rect.width + available_space['left_margin'] + available_space['right_margin'] * 1.5  # æ›´ç§¯æåˆ©ç”¨å³è¾¹è·
        )
        
        max_display_height = min(
            page_height * 0.98,  # æå‡åˆ°98%é¡µé¢é«˜åº¦åˆ©ç”¨ç‡
            original_rect.height + available_space['top_margin'] + available_space['bottom_margin'] * 1.5  # æ›´ç§¯æåˆ©ç”¨ä¸‹è¾¹è·
        )
        
        # ç­–ç•¥1: æ™ºèƒ½æ˜¾ç¤ºå¯†åº¦ä¼˜åŒ–
        # ç›®æ ‡æ˜¾ç¤ºå¯†åº¦: 1.5-2.0 åƒç´ /ç‚¹ (æœ€ä½³è§†è§‰æ•ˆæœ)
        optimal_density = 1.8  # æœ€ä½³æ˜¾ç¤ºå¯†åº¦
        min_density = 1.2      # æœ€å°å¯æ¥å—å¯†åº¦
        max_density = 3.0      # æœ€å¤§å¯æ¥å—å¯†åº¦
        
        # è®¡ç®—åŸºäºæœ€ä½³å¯†åº¦çš„ç›®æ ‡æ˜¾ç¤ºå°ºå¯¸
        optimal_display_width = upscaled_width / optimal_density
        optimal_display_height = upscaled_height / optimal_density
        
        # åˆå§‹ç›®æ ‡å°ºå¯¸ï¼ˆä¼˜å…ˆè€ƒè™‘æœ€ä½³æ˜¾ç¤ºå¯†åº¦ï¼‰
        target_width = optimal_display_width
        target_height = optimal_display_height
        
        # å¦‚æœæœ€ä½³å°ºå¯¸è¶…å‡ºå¯ç”¨ç©ºé—´ï¼Œåˆ™æŒ‰æ¯”ä¾‹ç¼©æ”¾
        if target_width > max_display_width or target_height > max_display_height:
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒå®½é«˜æ¯”
            scale_w = max_display_width / target_width
            scale_h = max_display_height / target_height
            scale = min(scale_w, scale_h)
            
            target_width = target_width * scale
            target_height = target_height * scale
            
            # æ£€æŸ¥ç¼©æ”¾åçš„æ˜¾ç¤ºå¯†åº¦
            final_density_x = upscaled_width / target_width
            final_density_y = upscaled_height / target_height
            avg_density = (final_density_x + final_density_y) / 2
            
            if log_callback:
                log_callback(f"        ğŸ”„ ç©ºé—´é™åˆ¶ç¼©æ”¾: æ¯”ä¾‹ {scale:.2f}, æ˜¾ç¤ºå¯†åº¦ {avg_density:.1f} åƒç´ /ç‚¹")
        else:
            if log_callback:
                log_callback(f"        âœ¨ æœ€ä½³å¯†åº¦æ˜¾ç¤º: {optimal_density:.1f} åƒç´ /ç‚¹")
        
        # æ™ºèƒ½æœ€å°å°ºå¯¸ä¿è¯ï¼ˆåŸºäºæ˜¾ç¤ºå¯†åº¦å’ŒåŸå§‹å°ºå¯¸ï¼‰
        # ç¡®ä¿æ˜¾ç¤ºå¯†åº¦ä¸ä¼šè¿‡é«˜ï¼ŒåŒæ—¶ä¿è¯è§†è§‰æ”¹å–„
        max_acceptable_density = max_density
        min_width_by_density = upscaled_width / max_acceptable_density
        min_height_by_density = upscaled_height / max_acceptable_density
        
        # åŸå§‹å°ºå¯¸çš„æ™ºèƒ½æ”¾å¤§ï¼ˆè‡³å°‘1.2å€ï¼Œæœ€å¤š2.5å€ï¼‰
        min_width_by_original = original_rect.width * 1.2  # è‡³å°‘æ¯”åŸå§‹å¤§20%
        min_height_by_original = original_rect.height * 1.2
        max_width_by_original = original_rect.width * 2.5  # æœ€å¤šæ”¾å¤§2.5å€
        max_height_by_original = original_rect.height * 2.5
        
        # é€‰æ‹©æ›´åˆç†çš„æœ€å°å°ºå¯¸
        min_width = max(min_width_by_density, min_width_by_original)
        min_height = max(min_height_by_density, min_height_by_original)
        
        # åº”ç”¨æœ€å°å°ºå¯¸çº¦æŸ
        if target_width < min_width or target_height < min_height:
            # æŒ‰æ¯”ä¾‹æ”¾å¤§åˆ°è‡³å°‘æœ€å°å°ºå¯¸
            scale_w = min_width / target_width if target_width < min_width else 1.0
            scale_h = min_height / target_height if target_height < min_height else 1.0
            scale = max(scale_w, scale_h)
            
            target_width = target_width * scale
            target_height = target_height * scale
            
            if log_callback:
                log_callback(f"        ğŸ“ åº”ç”¨æœ€å°å°ºå¯¸çº¦æŸ: ç¼©æ”¾ {scale:.2f}x")
        
        # åº”ç”¨æœ€å¤§å°ºå¯¸çº¦æŸï¼ˆé˜²æ­¢è¿‡åº¦æ”¾å¤§ï¼‰
        if target_width > max_width_by_original or target_height > max_height_by_original:
            scale_w = max_width_by_original / target_width if target_width > max_width_by_original else 1.0
            scale_h = max_height_by_original / target_height if target_height > max_height_by_original else 1.0
            scale = min(scale_w, scale_h)
            
            target_width = target_width * scale
            target_height = target_height * scale
            
            if log_callback:
                log_callback(f"        ğŸ”’ åº”ç”¨æœ€å¤§å°ºå¯¸é™åˆ¶: ç¼©æ”¾ {scale:.2f}x")
        
        # æ™ºèƒ½å±…ä¸­ç­–ç•¥ï¼šä¼˜å…ˆè€ƒè™‘é¡µé¢å¯ç”¨ç©ºé—´
        # è®¡ç®—å¯ç”¨æ˜¾ç¤ºåŒºåŸŸçš„ä¸­å¿ƒç‚¹
        available_left = max(0, available_space.get('left_margin', 0))
        available_right = min(page_width, page_width - available_space.get('right_margin', 0))
        available_top = max(0, available_space.get('top_margin', 0))
        available_bottom = min(page_height, page_height - available_space.get('bottom_margin', 0))
        
        available_center_x = (available_left + available_right) / 2
        available_center_y = (available_top + available_bottom) / 2
        
        # å¦‚æœå¯ç”¨ç©ºé—´å¤ªå°ï¼Œåˆ™ä½¿ç”¨é¡µé¢ä¸­å¿ƒ
        if (available_right - available_left) < target_width * 1.1 or (available_bottom - available_top) < target_height * 1.1:
            # ä½¿ç”¨é¡µé¢ä¸­å¿ƒä½œä¸ºå‚è€ƒ
            center_x = page_width / 2
            center_y = page_height / 2
            if log_callback:
                log_callback(f"        ğŸ¯ ä½¿ç”¨é¡µé¢ä¸­å¿ƒå®šä½ ({center_x:.0f}, {center_y:.0f})")
        else:
            # ä½¿ç”¨å¯ç”¨ç©ºé—´ä¸­å¿ƒï¼Œä½†è€ƒè™‘åŸå§‹ä½ç½®çš„åå¥½
            original_center_x = original_rect.x0 + original_rect.width / 2
            original_center_y = original_rect.y0 + original_rect.height / 2
            
            # åœ¨å¯ç”¨ç©ºé—´ä¸­å¿ƒå’ŒåŸå§‹ä¸­å¿ƒä¹‹é—´æ‰¾å¹³è¡¡
            center_x = (available_center_x + original_center_x) / 2
            center_y = (available_center_y + original_center_y) / 2
            
            # ç¡®ä¿ä¸­å¿ƒç‚¹åœ¨åˆç†èŒƒå›´å†…
            center_x = max(target_width/2, min(page_width - target_width/2, center_x))
            center_y = max(target_height/2, min(page_height - target_height/2, center_y))
            
            if log_callback:
                log_callback(f"        ğŸ¯ ä½¿ç”¨æ™ºèƒ½å±…ä¸­å®šä½ ({center_x:.0f}, {center_y:.0f})")
        
        new_x0 = center_x - target_width / 2
        new_y0 = center_y - target_height / 2
        new_x1 = new_x0 + target_width
        new_y1 = new_y0 + target_height
        
        # æ™ºèƒ½è¾¹ç•Œæ£€æŸ¥å’Œå°ºå¯¸è°ƒæ•´
        # æ·»åŠ å®‰å…¨è¾¹è·ï¼Œç¡®ä¿å›¾ç‰‡ä¸ä¼šç´§è´´é¡µé¢è¾¹ç¼˜
        safety_margin = 10  # 10pt å®‰å…¨è¾¹è·
        safe_page_width = page_width - 2 * safety_margin
        safe_page_height = page_height - 2 * safety_margin
        
        # å¦‚æœå›¾ç‰‡å°ºå¯¸è¶…å‡ºå®‰å…¨é¡µé¢èŒƒå›´ï¼Œéœ€è¦å…ˆç¼©æ”¾å†å±…ä¸­
        if target_width > safe_page_width or target_height > safe_page_height:
            # è®¡ç®—é€‚åº”å®‰å…¨é¡µé¢çš„ç¼©æ”¾æ¯”ä¾‹
            scale_w = safe_page_width / target_width if target_width > safe_page_width else 1.0
            scale_h = safe_page_height / target_height if target_height > safe_page_height else 1.0
            boundary_scale = min(scale_w, scale_h) * 0.95  # é¢å¤–5%çš„å®‰å…¨ç³»æ•°
            
            # åº”ç”¨è¾¹ç•Œç¼©æ”¾
            target_width = target_width * boundary_scale
            target_height = target_height * boundary_scale
            
            if log_callback:
                log_callback(f"        ğŸ”’ è¾¹ç•Œçº¦æŸç¼©æ”¾: {boundary_scale:.2f}x (å«å®‰å…¨è¾¹è·)")
        
        # é‡æ–°è®¡ç®—å±…ä¸­ä½ç½®ï¼ˆåŸºäºè°ƒæ•´åçš„å°ºå¯¸ï¼‰
        # ä½¿ç”¨ä¹‹å‰è®¡ç®—çš„æ™ºèƒ½ä¸­å¿ƒä½ç½®ï¼Œè€Œä¸æ˜¯åŸå§‹å›¾ç‰‡ä¸­å¿ƒ
        new_x0 = center_x - target_width / 2
        new_y0 = center_y - target_height / 2
        new_x1 = new_x0 + target_width
        new_y1 = new_y0 + target_height
        
        # è¾¹ç•Œå¾®è°ƒï¼ˆç¡®ä¿å®Œå…¨åœ¨å®‰å…¨åŒºåŸŸå†…ä¸”å°½é‡å±…ä¸­ï¼‰
        # æ°´å¹³æ–¹å‘è°ƒæ•´
        if new_x0 < safety_margin:
            new_x0 = safety_margin
            new_x1 = new_x0 + target_width
        elif new_x1 > page_width - safety_margin:
            new_x1 = page_width - safety_margin
            new_x0 = new_x1 - target_width
        
        # å‚ç›´æ–¹å‘è°ƒæ•´
        if new_y0 < safety_margin:
            new_y0 = safety_margin
            new_y1 = new_y0 + target_height
        elif new_y1 > page_height - safety_margin:
            new_y1 = page_height - safety_margin
            new_y0 = new_y1 - target_height
        
        # æœ€ç»ˆå°ºå¯¸ç¡®è®¤
        final_width = new_x1 - new_x0
        final_height = new_y1 - new_y0
        
        # éªŒè¯æœ€ç»ˆä½ç½®
        if log_callback:
            if (new_x0 >= safety_margin and new_y0 >= safety_margin and 
                new_x1 <= page_width - safety_margin and new_y1 <= page_height - safety_margin):
                log_callback(f"        âœ… ä½ç½®éªŒè¯: å›¾ç‰‡å®Œå…¨åœ¨å®‰å…¨åŒºåŸŸå†…")
            elif new_x0 >= 0 and new_y0 >= 0 and new_x1 <= page_width and new_y1 <= page_height:
                log_callback(f"        ğŸ“ ä½ç½®éªŒè¯: å›¾ç‰‡åœ¨é¡µé¢èŒƒå›´å†…ä½†æ¥è¿‘è¾¹ç¼˜")
            else:
                log_callback(f"        âš ï¸  ä½ç½®è­¦å‘Š: å›¾ç‰‡å¯èƒ½è¶…å‡ºé¡µé¢è¾¹ç•Œ")
        
        # è®¡ç®—æœ€ç»ˆæ˜¾ç¤ºæ•ˆæœç»Ÿè®¡
        if log_callback:
            scale_factor_x = final_width / original_rect.width if original_rect.width > 0 else 1
            scale_factor_y = final_height / original_rect.height if original_rect.height > 0 else 1
            avg_scale = (scale_factor_x + scale_factor_y) / 2
            
            # è®¡ç®—æœ€ç»ˆæ˜¾ç¤ºå¯†åº¦
            final_density_x = upscaled_width / final_width if final_width > 0 else 0
            final_density_y = upscaled_height / final_height if final_height > 0 else 0
            avg_final_density = (final_density_x + final_density_y) / 2
            
            # è®¡ç®—é¡µé¢è¦†ç›–ç‡æ”¹å–„
            original_area = original_rect.width * original_rect.height
            final_area = final_width * final_height
            page_area = page_width * page_height
            coverage_improvement = (final_area - original_area) / page_area * 100 if page_area > 0 else 0
            
            log_callback(f"        ğŸ“º æœ€ç»ˆæ˜¾ç¤º: {final_width:.0f}x{final_height:.0f}pt (æ”¾å¤§ {avg_scale:.1f}x)")
            log_callback(f"        ğŸ¯ æ˜¾ç¤ºå¯†åº¦: {avg_final_density:.1f} åƒç´ /ç‚¹")
            log_callback(f"        ğŸ“ˆ é¡µé¢è¦†ç›–æå‡: +{coverage_improvement:.1f}%")
        
        return fitz.Rect(new_x0, new_y0, new_x1, new_y1)
    
    def _calculate_optimized_rect(self, original_rect, available_space, img_aspect_ratio, 
                                page_width, page_height, log_callback=None):
        """è®¡ç®—ä¼˜åŒ–åçš„å›¾åƒçŸ©å½¢ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰
        
        Args:
            original_rect: åŸå§‹å›¾åƒçŸ©å½¢
            available_space: å¯ç”¨ç©ºé—´ä¿¡æ¯
            img_aspect_ratio: å›¾åƒå®½é«˜æ¯”
            page_width: é¡µé¢å®½åº¦
            page_height: é¡µé¢é«˜åº¦
            log_callback: æ—¥å¿—å›è°ƒå‡½æ•°
            
        Returns:
            ä¼˜åŒ–åçš„å›¾åƒçŸ©å½¢
        """
        import fitz
        
        # è®¾ç½®æœ€å°å’Œæœ€å¤§ç¼©æ”¾æ¯”ä¾‹
        min_scale = 1.0  # ä¸ç¼©å°
        max_scale = 3.0  # æœ€å¤§æ”¾å¤§3å€
        
        # è®¡ç®—å¯ä»¥æ‰©å±•çš„æœ€å¤§å°ºå¯¸
        max_width = min(
            page_width * 0.9,  # ä¸è¶…è¿‡é¡µé¢å®½åº¦çš„90%
            original_rect.width + available_space['left_margin'] + available_space['right_margin']
        )
        
        max_height = min(
            page_height * 0.9,  # ä¸è¶…è¿‡é¡µé¢é«˜åº¦çš„90%
            original_rect.height + available_space['top_margin'] + available_space['bottom_margin']
        )
        
        # æ ¹æ®å›¾åƒå®½é«˜æ¯”è®¡ç®—æœ€ä½³å°ºå¯¸
        if img_aspect_ratio > 1:  # æ¨ªå‘å›¾åƒ
            new_width = min(max_width, original_rect.width * max_scale)
            new_height = new_width / img_aspect_ratio
            
            if new_height > max_height:
                new_height = min(max_height, original_rect.height * max_scale)
                new_width = new_height * img_aspect_ratio
        else:  # çºµå‘å›¾åƒ
            new_height = min(max_height, original_rect.height * max_scale)
            new_width = new_height * img_aspect_ratio
            
            if new_width > max_width:
                new_width = min(max_width, original_rect.width * max_scale)
                new_height = new_width / img_aspect_ratio
        
        # ç¡®ä¿ä¸å°äºåŸå§‹å°ºå¯¸
        new_width = max(new_width, original_rect.width)
        new_height = max(new_height, original_rect.height)
        
        # è®¡ç®—æ–°çš„ä½ç½®ï¼ˆå°½é‡å±…ä¸­ï¼Œä½†è€ƒè™‘é¡µé¢å¸ƒå±€ï¼‰
        center_x = original_rect.x0 + original_rect.width / 2
        center_y = original_rect.y0 + original_rect.height / 2
        
        new_x0 = center_x - new_width / 2
        new_y0 = center_y - new_height / 2
        new_x1 = new_x0 + new_width
        new_y1 = new_y0 + new_height
        
        # ç¡®ä¿ä¸è¶…å‡ºé¡µé¢è¾¹ç•Œ
        if new_x0 < 0:
            new_x1 -= new_x0
            new_x0 = 0
        elif new_x1 > page_width:
            new_x0 -= (new_x1 - page_width)
            new_x1 = page_width
        
        if new_y0 < 0:
            new_y1 -= new_y0
            new_y0 = 0
        elif new_y1 > page_height:
            new_y0 -= (new_y1 - page_height)
            new_y1 = page_height
        
        return fitz.Rect(new_x0, new_y0, new_x1, new_y1)
    
    def _insert_upscaled_image(self, page, rect, image_path, log_callback=None):
        """ä¼˜åŒ–çš„å›¾åƒæ’å…¥æ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨ä¼˜åŒ–åçš„çŸ©å½¢å°ºå¯¸æ˜¾ç¤ºé«˜æ¸…åŒ–å›¾åƒ"""
        try:
            # è·å–å›¾åƒå®é™…å°ºå¯¸
            with Image.open(image_path) as img:
                img_width, img_height = img.size
            
            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„çŸ©å½¢åŒºåŸŸï¼ˆè¿™ä¸ªçŸ©å½¢å·²ç»é€šè¿‡_calculate_display_rectä¼˜åŒ–è¿‡ï¼‰
            # ä¸å†è¿›è¡Œé¢å¤–çš„ç¼©æ”¾è®¡ç®—ï¼Œè®©é«˜æ¸…åŒ–å›¾åƒä»¥ä¼˜åŒ–åçš„å°ºå¯¸æ˜¾ç¤º
            page.insert_image(rect, filename=image_path)
            
            if log_callback:
                log_callback(f"        ğŸ“ é«˜æ¸…åŒ–å›¾åƒæ’å…¥: {img_width}x{img_height} æ˜¾ç¤ºä¸º {rect.width:.0f}x{rect.height:.0f}")
                
        except Exception as e:
            logger.error(f"ä¼˜åŒ–å›¾åƒæ’å…¥å¤±è´¥: {e}")
            # å›é€€åˆ°åŸå§‹æ–¹æ³•
            page.insert_image(rect, filename=image_path)
    
    def _cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for temp_file in self._temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {temp_file}, é”™è¯¯: {e}")
        self._temp_files.clear()
    
    def _optimize_batch_processing(self, image_list, upscale_method, log_callback=None):
        """æ‰¹å¤„ç†ä¼˜åŒ– - å¯¹å¤šä¸ªå›¾åƒè¿›è¡Œæ‰¹é‡å¤„ç†ä»¥æå‡GPUåˆ©ç”¨ç‡"""
        if not image_list or len(image_list) < 2:
            return None
            
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡Œæ‰¹å¤„ç†
            gpu_available = self._check_gpu_availability()
            if not gpu_available:
                return None
                
            if log_callback:
                log_callback(f"      ğŸ”„ å¯ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼Œå¤„ç† {len(image_list)} ä¸ªå›¾åƒ")
                
            # è¿™é‡Œå¯ä»¥å®ç°æ‰¹å¤„ç†é€»è¾‘
            # ç›®å‰è¿”å›Noneï¼Œä½¿ç”¨å•ä¸ªå¤„ç†æ¨¡å¼
            return None
            
        except Exception as e:
            logger.error(f"æ‰¹å¤„ç†ä¼˜åŒ–å¤±è´¥: {e}")
            return None
    
    def get_default_options(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤è½¬æ¢é€‰é¡¹"""
        return {
            'upscale_method': 'photo',
            'scale_factor': 2,
            'quality': 95,
            'enable_gpu': True,
            'batch_size': 4  # GPUæ‰¹å¤„ç†å¤§å°
        }
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for temp_file in self._temp_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        self._temp_files.clear()

# æ’ä»¶æ³¨å†Œå‡½æ•°
def register_converter():
    """æ³¨å†Œè½¬æ¢å™¨æ’ä»¶"""
    return PDFUpscaleConverter()

# æ’ä»¶å…ƒæ•°æ®
CONVERTER_METADATA = ConverterMetadata(
    name="pdf_upscale",
    description="PDFé«˜æ¸…åŒ–è½¬æ¢å™¨ - ä½¿ç”¨AIç®—æ³•æå‡PDFä¸­å›¾åƒçš„åˆ†è¾¨ç‡å’Œè´¨é‡",
    version="1.0.0",
    author="PDF Converter Team",
    supported_input_formats=["pdf"],
    supported_output_formats=["pdf"],
    dependencies=["PyMuPDF", "Pillow"],
    priority=10
)